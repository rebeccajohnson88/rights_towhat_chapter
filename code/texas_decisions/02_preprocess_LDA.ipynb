{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## view all outputs\n",
    "import warnings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## pdf reading\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "import io\n",
    "\n",
    "## dataframe\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "## preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "## add punctuation and some application-specific words\n",
    "## to stopword list\n",
    "from nltk.stem.porter import *\n",
    "porter = PorterStemmer()\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "## lda\n",
    "from gensim import corpora\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Loading data\n",
    "\n",
    "\n",
    "**Task**: unzip the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store path to where the zip file\n",
    "base_path = \"/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/\" \n",
    "\n",
    "## unzip at that location if have not yet unzipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: to build the first part of your loop, extract two strings from the filenames (stored in hearing_filenames)\n",
    "\n",
    "1. The month\n",
    "2. The year\n",
    "\n",
    "Below provides some code for one file to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in texas filings names\n",
    "texas_wnces = pd.read_csv(base_path + \"intermediate/texas_filings_wnces.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean the docket number\n",
    "texas_wnces['clean_docket'] = texas_wnces['nan_docket_#'].astype(str).str.replace(\"\\\\s+\", \"\")\n",
    "\n",
    "## can then merge with frpl later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001-SE-0916_North%20East%20ISD.pdf',\n",
       " '002-SE-0917_El%20Paso%20ISD.pdf',\n",
       " '006-SE-0913_Leander.pdf',\n",
       " '009-SE-0916_Huntsville%20ISD.pdf',\n",
       " '009-SE-0917_Riesel%20ISD.pdf',\n",
       " '010-SE-0915_Edinburg.pdf',\n",
       " '011-SE-0914_WestOrangeCove.pdf',\n",
       " '012-SE-0913_SpringHill.pdf',\n",
       " '014-SE-0916_Killeen%20ISD.pdf',\n",
       " '015-SE-0914_GrapevineColleyville.pdf',\n",
       " '016-SE-0916_Abilene%20ISD.pdf',\n",
       " '017-SE-0915_Pflugerville.pdf',\n",
       " '021-SE-1016_Kirbyville%20CISD.pdf',\n",
       " '024-SE-0915_Gregory-Portland.pdf',\n",
       " '024-SE-1016_Northside.pdf',\n",
       " '027-SE-1017_Conroe%20ISD.pdf',\n",
       " '028-SE-0914_Canyon.pdf',\n",
       " '030-SE-1016_Cedar%20Hill%20ISD.pdf',\n",
       " '032-SE-0914_Robstown.pdf',\n",
       " '035-SE-1017_Leander%20ISD.pdf',\n",
       " '039-SE-1013_Lewisville.pdf',\n",
       " '040-SE-1017_Huntsville%20ISD.pdf',\n",
       " '041-SE-1013_Mesquite.pdf',\n",
       " '047-SE-1014_SanAntonio.pdf',\n",
       " '050-SE-1014_Lamar.pdf',\n",
       " '052-SE-1014_Dallas.pdf',\n",
       " '056-SE-1116_Round%20Rock%20ISD.pdf',\n",
       " '062-SE-1116_Georgetown%20ISD.pdf',\n",
       " '062-SE-1118_Kirbyville%20CISD.pdf',\n",
       " '066-SE-1013_Forney.pdf',\n",
       " '068-SE-1015_SpringBranch.pdf',\n",
       " '069-SE-1116_Uplift%20Education.pdf',\n",
       " '072-SE-1116_Clear%20Creek%20ISD.pdf',\n",
       " '074-SE-1113_GrapevineColleyville.pdf',\n",
       " '080-SE-1113_Canyon.pdf',\n",
       " '092-SE-1216_Riesel%20ISD.pdf',\n",
       " '092-SE-1217_Lewisville%20ISD.pdf',\n",
       " '098-SE-0117_North%20East%20ISD.pdf',\n",
       " '099-SE-0117_Northside%20ISD.pdf',\n",
       " '101-SE-0117_Copperas%20Cove%20ISD.pdf',\n",
       " '102-SE-1115_Riesel.pdf',\n",
       " '111-SE-1215_Houston.pdf',\n",
       " '117-SE-0217_Pearland%20ISD.pdf',\n",
       " '120-SE-0114_WestOrange.pdf',\n",
       " '121-SE-0118_Austin%20ISD.pdf',\n",
       " '126-SE-0114_HurstEulessBeford.pdf',\n",
       " '129-SE-0114_Houston.pdf',\n",
       " '129-SE-0116_Bullard.pdf',\n",
       " '130-SE-0213_Manor.pdf',\n",
       " '136-SE-0116_Killeen1.pdf',\n",
       " '138-SE-0214_Silsbee.pdf',\n",
       " '141-SE-0214_CarrolltonFarmersBranch.pdf',\n",
       " '144-SE-0216_Galveston.pdf',\n",
       " '145-SE-0115_AransasPass.pdf',\n",
       " '146-SE-0218_Klein%20ISD.pdf',\n",
       " '147-SE-0313_Bishop.pdf',\n",
       " '148-SE-0317_Waxahachie%20ISD.pdf',\n",
       " '149-SE-0214_Spring.pdf',\n",
       " '156-SE-0317_Lancaster%20ISD.pdf',\n",
       " '157-SE-0317_Lubbock%20Cooper%20ISD.pdf',\n",
       " '158-SE-0317_Lubbock-Cooper%20ISD.pdf',\n",
       " '162-SE-0214_Beaumont.pdf',\n",
       " '163-SE-0214_AransasPass.pdf',\n",
       " '163-SE-0215_Galveston.pdf',\n",
       " '166-SE-0216_Allen.pdf',\n",
       " '167-SE-0215_SanAntonio.pdf',\n",
       " '172-SE-0318A_Cypress-Fairbanks%20ISD.pdf',\n",
       " '175-SE-0316_Warren.pdf',\n",
       " '179-SE-0317_Clear%20Creek%20ISD.pdf',\n",
       " '183-SE-0417_Klein%20ISD.pdf',\n",
       " '185-SE-0418_Conroe%20ISD.pdf',\n",
       " '186-SE-0417_Austin%20ISD.pdf',\n",
       " '188-SE-0314_Mercedes.pdf',\n",
       " '194-SE-0413_Kingsville.pdf',\n",
       " '195-SE-0417_Port%20Arthur%20ISD.pdf',\n",
       " '200-SE-0315_HardinJefferson.pdf',\n",
       " '206-SE-0414_ClearCreek.pdf',\n",
       " '208-SE-0517_Spring%20Branch%20ISD.pdf',\n",
       " '209-SE-0414_Lewisville.pdf',\n",
       " '214-SE-0517_Vernon%20ISD.pdf',\n",
       " '218-SE-0517_Northside%20ISD.pdf',\n",
       " '219-SE-0415_HighlandPark.pdf',\n",
       " '223-SE-0416_Leander%20ISD.pdf',\n",
       " '223-SE-0517_El%20Paso%20ISD.pdf',\n",
       " '224-SE-0418_Klein%20ISD.pdf',\n",
       " '224-SE-0517_Smithville%20ISD.pdf',\n",
       " '226-SE-0517_Leander%20ISD.pdf',\n",
       " '227-SE-0414_TSD.pdf',\n",
       " '231-SE-0415_Edinburg.pdf',\n",
       " '241-SE-0518_Florence%20ISD.pdf',\n",
       " '241-SE-0613_Killeen1.pdf',\n",
       " '248-SE-0617_Houston%20ISD.pdf',\n",
       " '249-SE-0617_Pearland%20ISD.pdf',\n",
       " '250-SE-0617_Argyle%20ISD.pdf',\n",
       " '254-SE-0617_Northwest%20ISD.pdf',\n",
       " '255-SE-0614_CedarHill.pdf',\n",
       " '255-SE-0617_Judson%20ISD.pdf',\n",
       " '260-SE-0613_Seashore.pdf',\n",
       " '263-SE-0717_Riesel%20ISD.pdf',\n",
       " '267-SE-0516_LeanderISD.pdf',\n",
       " '268-SE-0614_HardinJefferson.pdf',\n",
       " '276-SE-0817_Cleveland%20ISD.pdf',\n",
       " '280-SE-0817_Leander%20ISD.pdf',\n",
       " '282-SE-0515_NorthEast.pdf',\n",
       " '284-SE-0817_Dallas%20ISD.pdf',\n",
       " '286-SE-0616_Killeen%20ISD.pdf',\n",
       " '287-SE-0515_AlamoHeights.pdf',\n",
       " '290-SE-0814_Houston.pdf',\n",
       " '292-SE-0814_ClearCreek.pdf',\n",
       " '304-SE-0814_Lewisville.pdf',\n",
       " '305-SE-0616_Conroe.pdf',\n",
       " '312-SE-0716_NorthsideISD.pdf',\n",
       " '316-SE-0716_Quinlan%20ISD.pdf',\n",
       " '322-SE-0615_Desoto.pdf',\n",
       " '332-SE-0816_Tomball.pdf',\n",
       " '335-SE-0715_Tomball.pdf',\n",
       " '346-SE-0715_SpringBranch.pdf',\n",
       " '355-SE-0815_Houston.pdf',\n",
       " '369-SE-0815_Bastrop.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'001-SE-0916'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get list of pathna\n",
    "path_hearings = base_path  + \"hearings\"\n",
    "os.chdir(path_hearings)\n",
    "hearing_filenames = glob.glob(\"*pdf*\")\n",
    "hearing_filenames\n",
    "\n",
    "docket_pattern = re.sub(\"\\\\_.*\", \"\", hearing_filenames[0])\n",
    "docket_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: now that you've build the two building blocks-- a given hearing pdf's month and year-- iterate through the first five of the hearing pdfs, read it in, and store in a dictionary where the key is formatted as: \"[nameofmonth]_[year]_i\", where i is the element of the list (otherwise, python would overwrite the value each time two hearings have the same month/year)\n",
    "\n",
    "Note: this takes some time to run due to the pdf conversion; so test the loop with the first five and in the next task, you'll read in data that already has it stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hearing_pdf(one_path):\n",
    "    text_hearing = convert_pdf_to_txt(one_path)\n",
    "    extract_docket = re.sub(\".*hearings/\", \"\", one_path)\n",
    "    return extract_docket, text_hearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/hearings/001-SE-0916_North%20East%20ISD.pdf',\n",
       " '/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/hearings/002-SE-0917_El%20Paso%20ISD.pdf',\n",
       " '/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/hearings/006-SE-0913_Leander.pdf',\n",
       " '/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/hearings/009-SE-0916_Huntsville%20ISD.pdf']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'001-SE-0916_North%20East%20ISD.pdf'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## iterate through files and use pdf to text function to convert\n",
    "## store in list\n",
    "store_files = dict()\n",
    "hearings_withpath = [path_hearings + \"/\" + one_filename for one_filename in hearing_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run external script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Read in the data: data_raw.pkl using the pd.read_pickle command. Parse the month_year column parse into one column for month, another for year. Finally, add an ID to the hearing (order doesn't matter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docket_num</th>\n",
       "      <th>docket_num_clean</th>\n",
       "      <th>(adv./tot.)_issues</th>\n",
       "      <th>date_hearina</th>\n",
       "      <th>date_last_order</th>\n",
       "      <th>due_date_decision</th>\n",
       "      <th>failed_extract_isd</th>\n",
       "      <th>isd_init</th>\n",
       "      <th>nan_decision_id</th>\n",
       "      <th>...</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>DISTRICT_C</th>\n",
       "      <th>NCES_DISTR</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>Shape_area</th>\n",
       "      <th>Shape_len</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>statelevel_id</th>\n",
       "      <th>clean_docket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...</td>\n",
       "      <td>001-SE-0916_North%20East%20ISD.pdf</td>\n",
       "      <td>001-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-05-03 00:00:00</td>\n",
       "      <td>1917-07-13 00:00:00</td>\n",
       "      <td>1916-11-14 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>11963</td>\n",
       "      <td>...</td>\n",
       "      <td>015-910</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>4832940.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.427700e+08</td>\n",
       "      <td>113966.846833</td>\n",
       "      <td>4.563349e+08</td>\n",
       "      <td>131484.820323</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>001-SE-0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...</td>\n",
       "      <td>002-SE-0917_El%20Paso%20ISD.pdf</td>\n",
       "      <td>002-SE-0917</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1918-03-28 00:00:00</td>\n",
       "      <td>1918-05-22 00:00:00</td>\n",
       "      <td>1917-12-16 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>13035</td>\n",
       "      <td>...</td>\n",
       "      <td>071-902</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>4818300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.475646e+08</td>\n",
       "      <td>149222.911954</td>\n",
       "      <td>7.646046e+08</td>\n",
       "      <td>176412.992072</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>002-SE-0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...</td>\n",
       "      <td>006-SE-0913_Leander.pdf</td>\n",
       "      <td>006-SE-0913</td>\n",
       "      <td>0/3</td>\n",
       "      <td>1913-12-16 00:00:00</td>\n",
       "      <td>1914-01-13 00:00:00</td>\n",
       "      <td>1913-11-19 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>8953</td>\n",
       "      <td>...</td>\n",
       "      <td>246-913</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>4827030.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.158609e+08</td>\n",
       "      <td>153901.806353</td>\n",
       "      <td>7.002723e+08</td>\n",
       "      <td>179284.138511</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>006-SE-0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...</td>\n",
       "      <td>009-SE-0916_Huntsville%20ISD.pdf</td>\n",
       "      <td>009-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1916-12-14 00:00:00</td>\n",
       "      <td>1917-01-13 00:00:00</td>\n",
       "      <td>1916-11-27 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>11981</td>\n",
       "      <td>...</td>\n",
       "      <td>236-902</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>4824030.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.540681e+09</td>\n",
       "      <td>236179.714272</td>\n",
       "      <td>2.102015e+09</td>\n",
       "      <td>275948.886980</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>009-SE-0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...</td>\n",
       "      <td>009-SE-0917_Riesel%20ISD.pdf</td>\n",
       "      <td>009-SE-0917</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-10-18 00:00:00</td>\n",
       "      <td>1917-10-30 00:00:00</td>\n",
       "      <td>1917-11-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>13063</td>\n",
       "      <td>...</td>\n",
       "      <td>161-912</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>4837110.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.515967e+08</td>\n",
       "      <td>79558.750571</td>\n",
       "      <td>2.099805e+08</td>\n",
       "      <td>93589.855445</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>009-SE-0917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...   \n",
       "1  Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...   \n",
       "2   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...   \n",
       "3   \\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...   \n",
       "4  DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...   \n",
       "\n",
       "                           docket_num docket_num_clean (adv./tot.)_issues  \\\n",
       "0  001-SE-0916_North%20East%20ISD.pdf      001-SE-0916                0/1   \n",
       "1     002-SE-0917_El%20Paso%20ISD.pdf      002-SE-0917                2/7   \n",
       "2             006-SE-0913_Leander.pdf      006-SE-0913                0/3   \n",
       "3    009-SE-0916_Huntsville%20ISD.pdf      009-SE-0916                0/1   \n",
       "4        009-SE-0917_Riesel%20ISD.pdf      009-SE-0917                0/1   \n",
       "\n",
       "          date_hearina      date_last_order    due_date_decision  \\\n",
       "0  1917-05-03 00:00:00  1917-07-13 00:00:00  1916-11-14 00:00:00   \n",
       "1  1918-03-28 00:00:00  1918-05-22 00:00:00  1917-12-16 00:00:00   \n",
       "2  1913-12-16 00:00:00  1914-01-13 00:00:00  1913-11-19 00:00:00   \n",
       "3  1916-12-14 00:00:00  1917-01-13 00:00:00  1916-11-27 00:00:00   \n",
       "4  1917-10-18 00:00:00  1917-10-30 00:00:00  1917-11-02 00:00:00   \n",
       "\n",
       "   failed_extract_isd  isd_init nan_decision_id     ...      DISTRICT  \\\n",
       "0                 0.0   15910.0           11963     ...       015-910   \n",
       "1                 0.0   71902.0           13035     ...       071-902   \n",
       "2                 0.0  246913.0            8953     ...       246-913   \n",
       "3                 0.0  236902.0           11981     ...       236-902   \n",
       "4                 0.0  161912.0           13063     ...       161-912   \n",
       "\n",
       "  DISTRICT_C NCES_DISTR  COLOR    Shape_area      Shape_len   Shape__Area  \\\n",
       "0    15910.0  4832940.0    3.0  3.427700e+08  113966.846833  4.563349e+08   \n",
       "1    71902.0  4818300.0    5.0  5.475646e+08  149222.911954  7.646046e+08   \n",
       "2   246913.0  4827030.0    6.0  5.158609e+08  153901.806353  7.002723e+08   \n",
       "3   236902.0  4824030.0    4.0  1.540681e+09  236179.714272  2.102015e+09   \n",
       "4   161912.0  4837110.0    4.0  1.515967e+08   79558.750571  2.099805e+08   \n",
       "\n",
       "   Shape__Length  statelevel_id clean_docket  \n",
       "0  131484.820323        15910.0  001-SE-0916  \n",
       "1  176412.992072        71902.0  002-SE-0917  \n",
       "2  179284.138511       246913.0  006-SE-0913  \n",
       "3  275948.886980       236902.0  009-SE-0916  \n",
       "4   93589.855445       161912.0  009-SE-0917  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_files_df_init = pd.read_pickle(\"/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/intermediate/hearings_raw.pkl\")\n",
    "store_files_df_init['docket_num_clean'] = store_files_df_init.docket_num.astype(str).str.replace(\"\\\\_.*\", \"\")\n",
    "\n",
    "## merge with nces ids\n",
    "store_files_df = pd.merge(store_files_df_init,\n",
    "                             texas_wnces,\n",
    "                             left_on = \"docket_num_clean\",\n",
    "                             right_on = \"clean_docket\",\n",
    "                             how = \"left\")\n",
    "\n",
    "\n",
    "## then later match with nces dem after preprocessing\n",
    "store_files_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using basic pandas string manipulation for text mining\n",
    "\n",
    "You already did some text mining to figure out one type of basic descriptive--- what month and year a parent filed a complaint.\n",
    "\n",
    "We're now going to have you did some text mining for a second type of descriptive information---are fathers or mothers mentioned more in the text? This relates to sociological work on gender inequalities in caregiving.\n",
    "\n",
    "I'll provide you with some example code, and then you'll generalize to the full corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: look at a few of the texts. To print the full text, you can wrap it in print(df.textcolumn[0]), print(df.textcolumn[1]), etc.. Scroll through to find examples of it mentioning mothers or fathers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(store_files_df.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: we will discuss more preprocessing in the next section but for now, create a new column 'text_lower' that makes all the words in the text column lowercase. For this, it's easiest to use the pandas string method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_files_df['text_lower'] = store_files_df.text.str.lower()\n",
    "\n",
    "\n",
    "wordpunct_tokenize = WordPunctTokenizer().tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: create a binary variable indicating *whether* (yes or no) the text contains words you think reflect mother. Similarly, create a binary variable indicating *whether* (yes or no) the text contains words you think reflect father. Then, create a third variable indicating whether:\n",
    "\n",
    "- The complaint mentions a child's mother only\n",
    "- The complaint mentions a child's father only\n",
    "- The complaint mentions both parents\n",
    "- The complain mentions neither parents\n",
    "\n",
    "\n",
    "Use df.varname.value_counts() to print the distribution of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mother_only       45\n",
       "neither_parent    39\n",
       "both_parents      32\n",
       "father_only        3\n",
       "Name: parent_cat, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_files_df['any_mother'] = np.where(store_files_df.text_lower.str.contains(\"mother|mom\"), 1, 0)\n",
    "store_files_df['any_father'] = np.where(store_files_df.text_lower.str.contains(\"father|dad\"), 1, 0)\n",
    "\n",
    "\n",
    "conditions = [(store_files_df.any_mother.eq(1) & store_files_df.any_father.eq(1)), \n",
    "            (store_files_df.any_mother.eq(1) & store_files_df.any_father.eq(0)),\n",
    "            (store_files_df.any_mother.eq(0) & store_files_df.any_father.eq(1)),\n",
    "            (store_files_df.any_mother.eq(0) & store_files_df.any_father.eq(0))]\n",
    "             \n",
    "choices = ['both_parents', 'mother_only', 'father_only', 'neither_parent']\n",
    "\n",
    "store_files_df['parent_cat'] = np.select(conditions, choices)\n",
    "store_files_df.parent_cat.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: you wonder if a complaint failing to mention both parents is (1) a reflection of both parents being involved, or (2) more related to longer complaints having more opportunities to discuss each of the parent's roles. To investigate this, we need to move to tools outside the pandas.varname.str.operation toolbox. Note that since we have not yet preprocessed the data, this count will be high, and will get much lower as we implement various preprocessing steps. \n",
    "\n",
    "For now, run the below code, and then we'll transition to nltk so you can learn more what it means. As a note, these counts will be very high because we have not yet removed punctuation!\n",
    "\n",
    "Then, use the df.groupby('grouping_varname')['continuous_varname'].mean() command to contrast the mean across each of the four levels of the factor variable you created in the previous task. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(one_complaint):\n",
    "    \n",
    "    complaint_tokens = wordpunct_tokenize(one_complaint)\n",
    "    n_tokens = len(set(complaint_tokens))\n",
    "    return(n_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docket_num</th>\n",
       "      <th>docket_num_clean</th>\n",
       "      <th>(adv./tot.)_issues</th>\n",
       "      <th>date_hearina</th>\n",
       "      <th>date_last_order</th>\n",
       "      <th>due_date_decision</th>\n",
       "      <th>failed_extract_isd</th>\n",
       "      <th>isd_init</th>\n",
       "      <th>nan_decision_id</th>\n",
       "      <th>...</th>\n",
       "      <th>Shape_len</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>statelevel_id</th>\n",
       "      <th>clean_docket</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>any_mother</th>\n",
       "      <th>any_father</th>\n",
       "      <th>parent_cat</th>\n",
       "      <th>unique_words_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...</td>\n",
       "      <td>001-SE-0916_North%20East%20ISD.pdf</td>\n",
       "      <td>001-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-05-03 00:00:00</td>\n",
       "      <td>1917-07-13 00:00:00</td>\n",
       "      <td>1916-11-14 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>11963</td>\n",
       "      <td>...</td>\n",
       "      <td>113966.846833</td>\n",
       "      <td>4.563349e+08</td>\n",
       "      <td>131484.820323</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>001-SE-0916</td>\n",
       "      <td>\\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\npetitioner \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both_parents</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...</td>\n",
       "      <td>002-SE-0917_El%20Paso%20ISD.pdf</td>\n",
       "      <td>002-SE-0917</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1918-03-28 00:00:00</td>\n",
       "      <td>1918-05-22 00:00:00</td>\n",
       "      <td>1917-12-16 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>13035</td>\n",
       "      <td>...</td>\n",
       "      <td>149222.911954</td>\n",
       "      <td>7.646046e+08</td>\n",
       "      <td>176412.992072</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>002-SE-0917</td>\n",
       "      <td>petitioner \\n\\nstudent, b/n/f parent, \\n \\n \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>father_only</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...</td>\n",
       "      <td>006-SE-0913_Leander.pdf</td>\n",
       "      <td>006-SE-0913</td>\n",
       "      <td>0/3</td>\n",
       "      <td>1913-12-16 00:00:00</td>\n",
       "      <td>1914-01-13 00:00:00</td>\n",
       "      <td>1913-11-19 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>8953</td>\n",
       "      <td>...</td>\n",
       "      <td>153901.806353</td>\n",
       "      <td>7.002723e+08</td>\n",
       "      <td>179284.138511</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>006-SE-0913</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nstudent \\n \\n ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both_parents</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...</td>\n",
       "      <td>009-SE-0916_Huntsville%20ISD.pdf</td>\n",
       "      <td>009-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1916-12-14 00:00:00</td>\n",
       "      <td>1917-01-13 00:00:00</td>\n",
       "      <td>1916-11-27 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>11981</td>\n",
       "      <td>...</td>\n",
       "      <td>236179.714272</td>\n",
       "      <td>2.102015e+09</td>\n",
       "      <td>275948.886980</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>009-SE-0916</td>\n",
       "      <td>\\n\\n \\n \\n \\n\\nstatement of the case \\n\\n \\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neither_parent</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...</td>\n",
       "      <td>009-SE-0917_Riesel%20ISD.pdf</td>\n",
       "      <td>009-SE-0917</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-10-18 00:00:00</td>\n",
       "      <td>1917-10-30 00:00:00</td>\n",
       "      <td>1917-11-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>13063</td>\n",
       "      <td>...</td>\n",
       "      <td>79558.750571</td>\n",
       "      <td>2.099805e+08</td>\n",
       "      <td>93589.855445</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>009-SE-0917</td>\n",
       "      <td>docket no. 009-se-0917 \\n\\npetitioner \\n\\nstud...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mother_only</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...   \n",
       "1  Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...   \n",
       "2   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...   \n",
       "3   \\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...   \n",
       "4  DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...   \n",
       "\n",
       "                           docket_num docket_num_clean (adv./tot.)_issues  \\\n",
       "0  001-SE-0916_North%20East%20ISD.pdf      001-SE-0916                0/1   \n",
       "1     002-SE-0917_El%20Paso%20ISD.pdf      002-SE-0917                2/7   \n",
       "2             006-SE-0913_Leander.pdf      006-SE-0913                0/3   \n",
       "3    009-SE-0916_Huntsville%20ISD.pdf      009-SE-0916                0/1   \n",
       "4        009-SE-0917_Riesel%20ISD.pdf      009-SE-0917                0/1   \n",
       "\n",
       "          date_hearina      date_last_order    due_date_decision  \\\n",
       "0  1917-05-03 00:00:00  1917-07-13 00:00:00  1916-11-14 00:00:00   \n",
       "1  1918-03-28 00:00:00  1918-05-22 00:00:00  1917-12-16 00:00:00   \n",
       "2  1913-12-16 00:00:00  1914-01-13 00:00:00  1913-11-19 00:00:00   \n",
       "3  1916-12-14 00:00:00  1917-01-13 00:00:00  1916-11-27 00:00:00   \n",
       "4  1917-10-18 00:00:00  1917-10-30 00:00:00  1917-11-02 00:00:00   \n",
       "\n",
       "   failed_extract_isd  isd_init nan_decision_id        ...          \\\n",
       "0                 0.0   15910.0           11963        ...           \n",
       "1                 0.0   71902.0           13035        ...           \n",
       "2                 0.0  246913.0            8953        ...           \n",
       "3                 0.0  236902.0           11981        ...           \n",
       "4                 0.0  161912.0           13063        ...           \n",
       "\n",
       "       Shape_len   Shape__Area  Shape__Length  statelevel_id clean_docket  \\\n",
       "0  113966.846833  4.563349e+08  131484.820323        15910.0  001-SE-0916   \n",
       "1  149222.911954  7.646046e+08  176412.992072        71902.0  002-SE-0917   \n",
       "2  153901.806353  7.002723e+08  179284.138511       246913.0  006-SE-0913   \n",
       "3  236179.714272  2.102015e+09  275948.886980       236902.0  009-SE-0916   \n",
       "4   79558.750571  2.099805e+08   93589.855445       161912.0  009-SE-0917   \n",
       "\n",
       "                                          text_lower  any_mother  any_father  \\\n",
       "0   \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\npetitioner \\n...           1           1   \n",
       "1  petitioner \\n\\nstudent, b/n/f parent, \\n \\n \\n...           0           1   \n",
       "2   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nstudent \\n \\n ...           1           1   \n",
       "3   \\n\\n \\n \\n \\n\\nstatement of the case \\n\\n \\n ...           0           0   \n",
       "4  docket no. 009-se-0917 \\n\\npetitioner \\n\\nstud...           1           0   \n",
       "\n",
       "       parent_cat unique_words_punct  \n",
       "0    both_parents               1535  \n",
       "1     father_only               1409  \n",
       "2    both_parents               1011  \n",
       "3  neither_parent                571  \n",
       "4     mother_only                865  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "parent_cat\n",
       "both_parents      1910.625000\n",
       "father_only       1240.666667\n",
       "mother_only       1609.111111\n",
       "neither_parent    1175.769231\n",
       "Name: unique_words_punct, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_files_df['unique_words_punct'] = store_files_df.text_lower.apply(count_words)\n",
    "store_files_df.head()\n",
    "\n",
    "store_files_df.groupby('parent_cat')['unique_words_punct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using ntlk for text preprocessing\n",
    "\n",
    "You probably noticed a few shortcomings of how we approached the previous task. In particular:\n",
    "    \n",
    "- We searched for a concept we already had in mind (gender of parent who's filing the complaint). What if we want to more inductively learn themes in the text data, without searching for pre-specified concepts?\n",
    "- Even if searching for a pre-specified concept, we were lucky in that mother and father have a limited number of words that can describe them. What if we wanted to investigate something where we're not really able to exhaustively enumerate the ways it can be described?\n",
    "\n",
    "That moves us to topic modeling, or ways to represent each complaint as having words that are drawn from latent themes/topics. The first step in topic modeling is pre-processing.  You probably noticed when reading through the texts that there are a lot of extra things--punctuation; words like \"of\"--that are not informative for learning themes in the text. so we're going to focus on that for the next part of the activity, using nltk, and then work on implementing a topic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: first, remove the stopwords using the built-in English stopwords within nltk (print to get a sense). Store the result in a new column: text_nostop_standard\n",
    "\n",
    "Compare the text in a couple of the documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_standard = set(stopwords.words('english'))\n",
    "#stop_words\n",
    "\n",
    "def remove_stop(row, colname, stopword_dict):\n",
    "    \n",
    "    string_of_col = str(row[colname])\n",
    "    try:\n",
    "        processed_string = \" \".join([i for i in wordpunct_tokenize(string_of_col) if \n",
    "                        i not in stopword_dict])  ## removed numeric\n",
    "        return(processed_string)\n",
    "    except:\n",
    "        processed_string = \"\" # to handle data errors where not actually text\n",
    "        return(processed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "petitioner \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "student b/n/f parent and    \n",
      "parent, \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "v.  \n",
      " \n",
      " \n",
      " \n",
      "n\n",
      "petitioner student b / n / f parent parent , v . north east independent school district , respondent\n"
     ]
    }
   ],
   "source": [
    "store_files_df['text_nostop_standard'] = store_files_df.apply(remove_stop,\n",
    "                                    axis = 1,\n",
    "                                   args = [\"text_lower\", stopwords_standard])\n",
    "print(store_files_df.text_lower[0][0:100])\n",
    "print(store_files_df.text_nostop_standard[0][0:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: check what type of object the standard stopwords are (type(object)). Update the standard stopwords to include some words specific to this context that we don't want to include, provided for you below in the additional_words_toadd list.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_words_toadd = [\"decision\", \"office\", \"petitioner\", \"texas\"]\n",
    "stopwords_standard.update(additional_words_toadd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: returning to the original text_lower column, remove stopwords using the updated stopword list. Store it as a column text_nostop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_files_df['text_nostop'] = store_files_df.apply(remove_stop,\n",
    "                                    axis = 1,\n",
    "                                   args = [\"text_lower\", stopwords_standard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: removing stopwords deletes entire words from the corpus. But we also want to preprocess the remaining words (1) to remove digits and punctuation (which we've decided are not relevant), and (2) reduce similar words to a common stem.\n",
    "\n",
    "Using the text_nostop column, perform the following additional preprocessing steps.\n",
    "- Stem using the porter stemmer\n",
    "- Only keep words where all the characters are letters (so removes punctuation and numbers)\n",
    "- Only keep words that are 3 characters or longer\n",
    "\n",
    "Store the preprocessed text in a new column: text_preprocess\n",
    "\n",
    "*Optional*: Rerun the above function to count the number of words in the processed text for each row and compare the distribution of count of words before preprocessing (text_lower) to the distribution of count of words after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processtext(row, colname):\n",
    "    \n",
    "    string_of_col = str(row[colname])\n",
    "    try:\n",
    "        processed_string = \" \".join([porter.stem(i.lower()) for i in wordpunct_tokenize(string_of_col) if \n",
    "                        i.lower().isalpha() and len(i) >=3])  \n",
    "        return(processed_string)\n",
    "    except:\n",
    "        processed_string = \"\" # to handle data errors where not actually text\n",
    "        return(processed_string)\n",
    "\n",
    "store_files_df['text_preprocess'] = store_files_df.apply(processtext,\n",
    "                                    axis = 1,\n",
    "                                   args = [\"text_nostop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: the package structural topic models we'll work on next works best with text that is still stored in a dataset with a column. Write the data with the following cols to csv--data_preprocess.csv---to use in STM:\n",
    "        \n",
    "- month\n",
    "- year\n",
    "- hearing ID\n",
    "- parent_cat\n",
    "- text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docket_num</th>\n",
       "      <th>docket_num_clean</th>\n",
       "      <th>(adv./tot.)_issues</th>\n",
       "      <th>date_hearina</th>\n",
       "      <th>date_last_order</th>\n",
       "      <th>due_date_decision</th>\n",
       "      <th>failed_extract_isd</th>\n",
       "      <th>isd_init</th>\n",
       "      <th>nan_decision_id</th>\n",
       "      <th>...</th>\n",
       "      <th>statelevel_id</th>\n",
       "      <th>clean_docket</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>any_mother</th>\n",
       "      <th>any_father</th>\n",
       "      <th>parent_cat</th>\n",
       "      <th>unique_words_punct</th>\n",
       "      <th>text_nostop_standard</th>\n",
       "      <th>text_nostop</th>\n",
       "      <th>text_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...</td>\n",
       "      <td>001-SE-0916_North%20East%20ISD.pdf</td>\n",
       "      <td>001-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-05-03 00:00:00</td>\n",
       "      <td>1917-07-13 00:00:00</td>\n",
       "      <td>1916-11-14 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>11963</td>\n",
       "      <td>...</td>\n",
       "      <td>15910.0</td>\n",
       "      <td>001-SE-0916</td>\n",
       "      <td>\\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\npetitioner \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both_parents</td>\n",
       "      <td>1535</td>\n",
       "      <td>petitioner student b / n / f parent parent , v...</td>\n",
       "      <td>student b / n / f parent parent , v . north ea...</td>\n",
       "      <td>student parent parent north east independ scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...</td>\n",
       "      <td>002-SE-0917_El%20Paso%20ISD.pdf</td>\n",
       "      <td>002-SE-0917</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1918-03-28 00:00:00</td>\n",
       "      <td>1918-05-22 00:00:00</td>\n",
       "      <td>1917-12-16 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>13035</td>\n",
       "      <td>...</td>\n",
       "      <td>71902.0</td>\n",
       "      <td>002-SE-0917</td>\n",
       "      <td>petitioner \\n\\nstudent, b/n/f parent, \\n \\n \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>father_only</td>\n",
       "      <td>1409</td>\n",
       "      <td>petitioner student , b / n / f parent , v . el...</td>\n",
       "      <td>student , b / n / f parent , v . el paso indep...</td>\n",
       "      <td>student parent paso independ school district r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...</td>\n",
       "      <td>006-SE-0913_Leander.pdf</td>\n",
       "      <td>006-SE-0913</td>\n",
       "      <td>0/3</td>\n",
       "      <td>1913-12-16 00:00:00</td>\n",
       "      <td>1914-01-13 00:00:00</td>\n",
       "      <td>1913-11-19 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>8953</td>\n",
       "      <td>...</td>\n",
       "      <td>246913.0</td>\n",
       "      <td>006-SE-0913</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nstudent \\n \\n ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both_parents</td>\n",
       "      <td>1011</td>\n",
       "      <td>student vs . leander . . . docket . 006 - se -...</td>\n",
       "      <td>student vs . leander . . . docket . 006 - se -...</td>\n",
       "      <td>student leander docket special educ hear offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...</td>\n",
       "      <td>009-SE-0916_Huntsville%20ISD.pdf</td>\n",
       "      <td>009-SE-0916</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1916-12-14 00:00:00</td>\n",
       "      <td>1917-01-13 00:00:00</td>\n",
       "      <td>1916-11-27 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>11981</td>\n",
       "      <td>...</td>\n",
       "      <td>236902.0</td>\n",
       "      <td>009-SE-0916</td>\n",
       "      <td>\\n\\n \\n \\n \\n\\nstatement of the case \\n\\n \\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neither_parent</td>\n",
       "      <td>571</td>\n",
       "      <td>statement case § § § § § § § hearing officer d...</td>\n",
       "      <td>statement case § § § § § § § hearing officer d...</td>\n",
       "      <td>statement case hear offic docket state special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...</td>\n",
       "      <td>009-SE-0917_Riesel%20ISD.pdf</td>\n",
       "      <td>009-SE-0917</td>\n",
       "      <td>0/1</td>\n",
       "      <td>1917-10-18 00:00:00</td>\n",
       "      <td>1917-10-30 00:00:00</td>\n",
       "      <td>1917-11-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>13063</td>\n",
       "      <td>...</td>\n",
       "      <td>161912.0</td>\n",
       "      <td>009-SE-0917</td>\n",
       "      <td>docket no. 009-se-0917 \\n\\npetitioner \\n\\nstud...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mother_only</td>\n",
       "      <td>865</td>\n",
       "      <td>docket . 009 - se - 0917 petitioner student , ...</td>\n",
       "      <td>docket . 009 - se - 0917 student , v . riesel ...</td>\n",
       "      <td>docket student riesel independ school district...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\nPetitioner \\n...   \n",
       "1  Petitioner \\n\\nSTUDENT, B/N/F PARENT, \\n \\n \\n...   \n",
       "2   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nSTUDENT \\n \\n ...   \n",
       "3   \\n\\n \\n \\n \\n\\nStatement of the Case \\n\\n \\n ...   \n",
       "4  DOCKET NO. 009-SE-0917 \\n\\nPetitioner \\n\\nSTUD...   \n",
       "\n",
       "                           docket_num docket_num_clean (adv./tot.)_issues  \\\n",
       "0  001-SE-0916_North%20East%20ISD.pdf      001-SE-0916                0/1   \n",
       "1     002-SE-0917_El%20Paso%20ISD.pdf      002-SE-0917                2/7   \n",
       "2             006-SE-0913_Leander.pdf      006-SE-0913                0/3   \n",
       "3    009-SE-0916_Huntsville%20ISD.pdf      009-SE-0916                0/1   \n",
       "4        009-SE-0917_Riesel%20ISD.pdf      009-SE-0917                0/1   \n",
       "\n",
       "          date_hearina      date_last_order    due_date_decision  \\\n",
       "0  1917-05-03 00:00:00  1917-07-13 00:00:00  1916-11-14 00:00:00   \n",
       "1  1918-03-28 00:00:00  1918-05-22 00:00:00  1917-12-16 00:00:00   \n",
       "2  1913-12-16 00:00:00  1914-01-13 00:00:00  1913-11-19 00:00:00   \n",
       "3  1916-12-14 00:00:00  1917-01-13 00:00:00  1916-11-27 00:00:00   \n",
       "4  1917-10-18 00:00:00  1917-10-30 00:00:00  1917-11-02 00:00:00   \n",
       "\n",
       "   failed_extract_isd  isd_init nan_decision_id  \\\n",
       "0                 0.0   15910.0           11963   \n",
       "1                 0.0   71902.0           13035   \n",
       "2                 0.0  246913.0            8953   \n",
       "3                 0.0  236902.0           11981   \n",
       "4                 0.0  161912.0           13063   \n",
       "\n",
       "                         ...                         statelevel_id  \\\n",
       "0                        ...                               15910.0   \n",
       "1                        ...                               71902.0   \n",
       "2                        ...                              246913.0   \n",
       "3                        ...                              236902.0   \n",
       "4                        ...                              161912.0   \n",
       "\n",
       "  clean_docket                                         text_lower  any_mother  \\\n",
       "0  001-SE-0916   \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n \\n\\npetitioner \\n...           1   \n",
       "1  002-SE-0917  petitioner \\n\\nstudent, b/n/f parent, \\n \\n \\n...           0   \n",
       "2  006-SE-0913   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nstudent \\n \\n ...           1   \n",
       "3  009-SE-0916   \\n\\n \\n \\n \\n\\nstatement of the case \\n\\n \\n ...           0   \n",
       "4  009-SE-0917  docket no. 009-se-0917 \\n\\npetitioner \\n\\nstud...           1   \n",
       "\n",
       "  any_father      parent_cat  unique_words_punct  \\\n",
       "0          1    both_parents                1535   \n",
       "1          1     father_only                1409   \n",
       "2          1    both_parents                1011   \n",
       "3          0  neither_parent                 571   \n",
       "4          0     mother_only                 865   \n",
       "\n",
       "                                text_nostop_standard  \\\n",
       "0  petitioner student b / n / f parent parent , v...   \n",
       "1  petitioner student , b / n / f parent , v . el...   \n",
       "2  student vs . leander . . . docket . 006 - se -...   \n",
       "3  statement case § § § § § § § hearing officer d...   \n",
       "4  docket . 009 - se - 0917 petitioner student , ...   \n",
       "\n",
       "                                         text_nostop  \\\n",
       "0  student b / n / f parent parent , v . north ea...   \n",
       "1  student , b / n / f parent , v . el paso indep...   \n",
       "2  student vs . leander . . . docket . 006 - se -...   \n",
       "3  statement case § § § § § § § hearing officer d...   \n",
       "4  docket . 009 - se - 0917 student , v . riesel ...   \n",
       "\n",
       "                                     text_preprocess  \n",
       "0  student parent parent north east independ scho...  \n",
       "1  student parent paso independ school district r...  \n",
       "2  student leander docket special educ hear offic...  \n",
       "3  statement case hear offic docket state special...  \n",
       "4  docket student riesel independ school district...  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_files_df.head()\n",
    "dem_char = pd.read_csv(base_path +\"cleaned/filings_withdem.csv\")\n",
    "\n",
    "dem_char_tomerge = dem_char[['nces_id', 'frpl_eligible_rate']]\n",
    "dem_char_tomerge['nces_id_tomerge'] = dem_char_tomerge.nces_id.astype(str)\n",
    "\n",
    "store_files_df['nces_id'] = store_files_df.NCES_DISTR.astype(str).str.replace(\"\\\\..*\", \"\")\n",
    "store_files_df_wdem = pd.merge(store_files_df,\n",
    "                              dem_char_tomerge,\n",
    "                              left_on = \"nces_id\",\n",
    "                            right_on = \"nces_id_tomerge\",\n",
    "                              how = \"left\")\n",
    "\n",
    "cols_touse = ['docket_num_clean', 'year_request', 'parent_cat',\n",
    "              'text_preprocess',\n",
    "              'nces_id_tomerge',\n",
    "              'frpl_eligible_rate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write version to csv to read into R\n",
    "store_files_df_wdem[cols_touse].to_csv(\"/Users/raj2/Dropbox/dph_hearing_decisions/data/texas/intermediate/hearings_preprocessed.csv\",\n",
    "            index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
