{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and link filings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccajohnson/opt/anaconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from tabula import read_pdf\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "## profiling\n",
    "import time\n",
    "\n",
    "## plotting\n",
    "from plotnine import *\n",
    "\n",
    "\n",
    "\n",
    "## first, clean case type\n",
    "def process_type(one_row):\n",
    "    \n",
    "    ## some dates so convert to string\n",
    "    one_string = str(one_row)\n",
    "    \n",
    "    ## clean for expedited discipline\n",
    "    clean_exp_1 = re.sub(r'(Exped(i)?(t)?(e)?|Discip)\\s+', r'\\1', one_string)\n",
    "    clean_exp_2 = re.sub(r'(Exped(i)?(t)?(e)?|Discip)\\s+', r'\\1', clean_exp_1)\n",
    "    \n",
    "    ## clean for lea\n",
    "    clean_lea = re.sub(r'(Aga(i)?(n)?)\\s+', r'\\1', clean_exp_2)\n",
    "    clean_lea_ret = clean_lea.lower()\n",
    "    \n",
    "    return(clean_lea_ret)\n",
    "\n",
    "def process_schoolname(one_name):\n",
    "    \n",
    "    ## uppercase\n",
    "    name_str = str(one_name)\n",
    "    name_upper = name_str.upper()\n",
    "\n",
    "    ## clean up schools\n",
    "    clean_school= re.sub(r'(SCHOO)\\s+', r'\\1', name_upper)\n",
    "    clean_middle = re.sub(r'(MIDD)\\s+', r'\\1', clean_school)\n",
    "    clean_ed = re.sub(r'(EDUCAT)\\s+', r'\\1', clean_middle)\n",
    "    \n",
    "    ## concat whitespace\n",
    "    replace_middle = re.sub(r'M(\\s)?I(\\s)?D(\\s)?D(\\s)?L(\\s)?E', r\"MIDDLE\", clean_ed)\n",
    "    replace_elem = re.sub(r'E(\\s)?L(\\s)?E(\\s)?M(\\s)?E(\\s)?N(\\s)?T(\\s)?A(\\s)?R(\\s)?Y', r\"ELEMENTARY\", replace_middle)\n",
    "    replace_school = re.sub(r'SCHOOI', \"SCHOOL\", replace_elem)\n",
    "    replace_campus = re.sub(r'C(\\s)?A(\\s)?M(\\s)?P(\\s)?U(\\s)?S', r\"CAMPUS\", replace_school)\n",
    "    replace_education = re.sub(r'E(\\s)?D(\\s)?U(\\s)?C(\\s)?A(\\s)?T(\\s)?I(\\s)?O(\\s)?N', r\"EDUCATION\", \n",
    "                               replace_campus)\n",
    "    \n",
    "    ## \n",
    "\n",
    "    return(replace_education)\n",
    "\n",
    "def replace_schooltype(one_string):\n",
    "    \n",
    "    es = re.sub(r'ES$|ELEMENTARY$', r'ELEMENTARY SCHOOL', one_string)\n",
    "    ec = re.sub(r'EC$', r'ELEMENTARY CAMPUS', es)\n",
    "    ms = re.sub(r'MS$|MIDDLE$', r'MIDDLE SCHOOL', ec)\n",
    "    hs = re.sub(r'HS$|HIGH$', r'HIGH SCHOOL', ms)\n",
    "    \n",
    "    return(hs)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def find_fuzzy_namematches(one_name: str, all_names: list, \n",
    "                           score_cutoff):\n",
    "    \n",
    "    ## extract matches above cutoff\n",
    "    all_abovecutoff = process.extractBests(one_name, all_names, score_cutoff = score_cutoff,\n",
    "                                          limit = 1)\n",
    "    \n",
    "    ## make into a dataframe (will thus only capture ones with matches)\n",
    "    all_abovecutoff_df = pd.DataFrame(list(all_abovecutoff), columns = ['matched_name', 'score'])\n",
    "    all_abovecutoff_df['original_name'] = one_name\n",
    "    return(all_abovecutoff_df)\n",
    "\n",
    "## resource-- package installation issues: https://bergvca.github.io/2017/10/14/super-fast-string-matching.html\n",
    "\n",
    "\n",
    "\n",
    "def replace_missing_nces(one_val):\n",
    "    \n",
    "    if one_val.isdigit():\n",
    "        final_val = one_val\n",
    "    else:\n",
    "        final_val = np.nan\n",
    "    return(final_val)\n",
    "\n",
    "def aggregate_crdc(var_col, value_col, \n",
    "                  data,\n",
    "                  id_col = [\"school_name\", \"ncessch\"],\n",
    "                  year_chosen = 2013, format = \"long\"):\n",
    "    \n",
    "    \n",
    "    ## shape from long to wide\n",
    "    if(format == \"long\"):\n",
    "        df_wide = pd.pivot_table(data.loc[data.year == year_chosen,\n",
    "                    id_col + [var_col] + [value_col]],\n",
    "                    index  = id_col, \n",
    "                    values = value_col,\n",
    "                    columns = var_col).reset_index()\n",
    "\n",
    "    \n",
    "    else:\n",
    "        df_wide = data.loc[data.year == year_chosen].copy()\n",
    "        \n",
    "    ## standardize columns\n",
    "    df_wide.columns = [re.sub(\"\\s+\", \"_\", col.upper()) \n",
    "                           for col in df_wide.columns]\n",
    "        \n",
    "    ## generate rates\n",
    "    sub_cols = set(df_wide.columns).difference([\"SCHOOL_NAME\", \"TOTAL\", 'YEAR',\n",
    "                                               'NCESSCH'])\n",
    "    \n",
    "    ## \n",
    "    for col in sub_cols:\n",
    "        df_wide[col] = pd.to_numeric(df_wide[col])\n",
    "        df_wide['TOTAL'] = pd.to_numeric(df_wide['TOTAL'])\n",
    "        df_wide['{}_rate'.format(col)] = df_wide[col]/df_wide['TOTAL']\n",
    "    \n",
    "    ## return\n",
    "    return(df_wide)\n",
    "    \n",
    "def aggregate_nces(var_pattern, varname_clean, id_col, \n",
    "                       cc_data_merged,\n",
    "                      enrollment_vars, base_name_raw):\n",
    "    \n",
    "    dem_vars = [col for col in cc_data_merged if var_pattern in col]\n",
    "    long_df = pd.melt(cc_data_merged[dem_vars + enrollment_vars + id_col],\n",
    "                       id_vars = id_col)\n",
    "    \n",
    "    ## create year versus dem col\n",
    "    long_df['clean_value_1'] = [replace_missing_nces(val) for val in long_df.value]\n",
    "    long_df['clean_value'] = pd.to_numeric(long_df.clean_value_1)\n",
    "    long_df['which_var'] = long_df.variable.astype(str).str.replace(\"\\\\_20.*\", \"\", regex = True)\n",
    "    replace_pattern = \"|\".join(long_df.which_var.unique())\n",
    "    long_df['which_year'] = [re.sub(replace_pattern, \"\", one_var) for one_var in long_df.variable]\n",
    "    long_toagg = long_df[id_col + ['which_var', 'which_year',\n",
    "                                           'clean_value']].reset_index()\n",
    "\n",
    "    ## do the aggregation \n",
    "    index_cols = id_col + [\"which_year\"]\n",
    "    df_wide = long_toagg.pivot_table(index  = index_cols,\n",
    "                                             values = 'clean_value',\n",
    "                                             columns = 'which_var').reset_index()\n",
    "\n",
    "    ## do the division\n",
    "    rate_varname = varname_clean + '_rate'\n",
    "    df_wide[rate_varname] = df_wide[var_pattern]/df_wide[base_name_raw]\n",
    "    #print(df_wide.head())\n",
    "    \n",
    "    ## return cleaned data\n",
    "    return(df_wide[id_col + [rate_varname] + ['which_year']])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load demographic data\n",
    "\n",
    "Two sources right now:\n",
    "\n",
    "- NCES Common Core --- SY 2012-2013 to SY 2017-2018\n",
    "- DOE Civil Rights Data collection --- focusing on SY 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 common core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 75-col limit in export-- first 75 cols\n",
    "cc_data_1 = pd.read_csv(\"../../raw_input/dc/dc_ccd.csv\")\n",
    "\n",
    "## \n",
    "cc_data_2 = pd.read_csv(\"../../raw_input/dc/dc_ccd_pull2.csv\",\n",
    "                       encoding= 'unicode_escape')\n",
    "\n",
    "## find overlapping cols\n",
    "cc_data_1_topull = cc_data_1.columns.difference(cc_data_2.columns).tolist() + \\\n",
    "                    [\"School Name\", \n",
    "                     \"School ID - NCES Assigned [Public School] Latest available year\"]\n",
    "## merge excluding\n",
    "cc_data_merged = pd.merge(cc_data_1[cc_data_1_topull], \n",
    "                          cc_data_2[[col for col in cc_data_2.columns if \n",
    "                            \"School ID - NCES Assigned [Public School] Latest available year\" not in col]], \n",
    "                          on = [\"School Name\"],\n",
    "                         how = \"left\")\n",
    "\n",
    "cc_cleancols = [re.sub(\"\\\\s+|\\\\[|\\\\]|\\\\(|\\\\)\", \"_\", x).upper() for x in cc_data_merged.columns]\n",
    "cc_data_merged.columns = cc_cleancols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean nces common core data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_vars = [col for col in cc_data_merged if 'TOTAL_STUDENTS' in col]\n",
    "base_name_raw = 'TOTAL_STUDENTS_ALL_GRADES__EXCLUDES_AE___PUBLIC_SCHOOL_'\n",
    "\n",
    "id_col = \"SCHOOL_NAME\"\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frpl_rate = aggregate_nces(var_pattern = \"FREE_LUNCH_ELIGIBLE__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"frpl_eligible\",\n",
    "                          id_col = ['SCHOOL_NAME'],\n",
    "                          cc_data_merged = cc_data_merged,\n",
    "                          enrollment_vars = enrollment_vars,\n",
    "                          base_name_raw = base_name_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_enrollment_vars = [col for col in cc_data_merged.columns if \"TOTAL_RACE\" in col]\n",
    "black_rate = aggregate_nces(var_pattern = \"BLACK_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"black\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                           id_col = ['SCHOOL_NAME'], cc_data_merged = cc_data_merged)\n",
    "white_rate = aggregate_nces(var_pattern = \"WHITE_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"white\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                           id_col = ['SCHOOL_NAME'], cc_data_merged = cc_data_merged)\n",
    "hisp_rate = aggregate_nces(var_pattern = \"HISPANIC_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"hispanic\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                          id_col = ['SCHOOL_NAME'], cc_data_merged = cc_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge into one df\n",
    "\n",
    "dfs = [df.set_index(['SCHOOL_NAME', \n",
    "                     'which_year']) for df in [frpl_rate, black_rate, white_rate, hisp_rate]]\n",
    "\n",
    "cc_dem_rates = pd.concat(dfs, axis=1).reset_index()\n",
    "cc_dem_rates.rename(columns = {'SCHOOL_NAME': \n",
    "                      'nces_name'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Civil rights data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    660\n",
       "2013    606\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in iep data \n",
    "## rj note: currently reading from extract but later switch to api\n",
    "crdc = pd.read_csv(\"../../raw_input/dc/EducationDataPortal_03.07.2020_disability.csv\")\n",
    "crdc.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate- omitting ncessch because it's \n",
    "## dist id and not school id\n",
    "iep_summary = aggregate_crdc(var_col = \"disability\", \n",
    "                            value_col = \"enrollment_crdc\", data = crdc,\n",
    "                            id_col= ['school_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read and clean discipline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crdc_largerpull = pd.read_csv(\"../../raw_input/dc/EducationDataPortal_03.08.2020_schools.csv\")\n",
    "\n",
    "## fill NA with 0\n",
    "crdc_largerpull_fill = crdc_largerpull.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## discipline\n",
    "discipline_cols = [col for col in crdc_largerpull_fill.columns if \n",
    "                  \"susp\" in col or \"expulsions\" in col or \"corporal\" in col]\n",
    "restr_secl_cols = [col for col in crdc_largerpull_fill.columns if \n",
    "                  \"restraint\" in col or \"seclusion\" in col]\n",
    "\n",
    "crdc_largerpull_fill['total_discipline'] = crdc_largerpull_fill[discipline_cols].sum(axis = 1)\n",
    "crdc_largerpull_fill['total_restraint_seclude'] = crdc_largerpull_fill[restr_secl_cols].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crdc_disc_foragg = crdc_largerpull_fill.loc[~crdc_largerpull_fill.enrollment.isin(['0',\n",
    "                                        'Not applicable']),\n",
    "                                        ['school_name', 'year',\n",
    "                                        'enrollment',\n",
    "                                        'total_discipline', 'ncessch']].copy()\n",
    "crdc_disc_foragg.rename(columns = {'enrollment':\n",
    "            'total'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_summary = aggregate_crdc(data = crdc_disc_foragg,\n",
    "                             var_col = \"total_discipline\", \n",
    "                            value_col = \"total_discipline\",\n",
    "                             format = \"wide\")\n",
    "crdc_res_foragg = crdc_largerpull_fill.loc[~crdc_largerpull_fill.enrollment.isin(['0',\n",
    "                                        'Not applicable']),\n",
    "                                        ['school_name', 'year', \"ncessch\",\n",
    "                                        'enrollment',\n",
    "                                        'total_restraint_seclude']].copy()\n",
    "crdc_res_foragg.rename(columns = {'enrollment':\n",
    "            'total'}, inplace = True)\n",
    "\n",
    "res_summary = aggregate_crdc(data = crdc_res_foragg,\n",
    "                             var_col = \"total_restraint_seclude\", \n",
    "                            value_col = \"total_restraint_seclude\",\n",
    "                             format = \"wide\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 merge the diff crdc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_summary.rename(columns = {'TOTAL': 'total_students_ressec_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "disc_summary.rename(columns = {'TOTAL': 'total_students_disc_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "iep_summary.rename(columns = {'TOTAL': 'total_students_iep_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "res_exclude_year = [col for col in res_summary.columns if col != \"YEAR\"]\n",
    "disc_exclude_year = [col for col in disc_summary.columns if col != \"YEAR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge restraint with iep\n",
    "iep_res = pd.merge(iep_summary, res_summary, how = \"left\",\n",
    "                  on = \"SCHOOL_NAME\",\n",
    "                  indicator = \"merge_ieprestraints\")\n",
    "dfs_crdc = pd.merge(iep_res, disc_summary[[col for col in disc_summary.columns if \n",
    "                                           col not in ['YEAR', 'NCESSCH']]],\n",
    "                   how = 'left',\n",
    "                   on = 'SCHOOL_NAME',\n",
    "                   indicator = \"merge_iepdisc\",\n",
    "                   suffixes = [\"_iepres\", \"_discipline\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add race from crdc using urban institute API\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "url = \"https://educationdata.urban.org/api/v1/schools/crdc/enrollment/2013/race/sex/\"\n",
    "response = urlopen(url)\n",
    "data = loads(response.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write the results to merge with the filings data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_crdc.to_csv(\"../../intermediate_objects/cleaned_df/dc_crdc_2013.csv\", index = False)\n",
    "dfs_crdc.to_pickle(\"../../intermediate_objects/cleaned_df/dc_crdc_2013.pkl\")\n",
    "\n",
    "cc_dem_rates.to_csv(\"../../intermediate_objects/cleaned_df/dc_ccd_2013.csv\", index = False)\n",
    "cc_dem_rates.to_pickle(\"../../intermediate_objects/cleaned_df/dc_ccd_2013.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
