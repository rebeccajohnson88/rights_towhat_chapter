{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and link filings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "## profiling\n",
    "import time\n",
    "\n",
    "## plotting\n",
    "from plotnine import *\n",
    "\n",
    "## dates\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "## first, clean case type\n",
    "def process_type(one_row):\n",
    "    \n",
    "    ## some dates so convert to string\n",
    "    one_string = str(one_row)\n",
    "    \n",
    "    ## clean for expedited discipline\n",
    "    clean_exp_1 = re.sub(r'(Exped(i)?(t)?(e)?|Discip)\\s+', r'\\1', one_string)\n",
    "    clean_exp_2 = re.sub(r'(Exped(i)?(t)?(e)?|Discip)\\s+', r'\\1', clean_exp_1)\n",
    "    \n",
    "    ## clean for lea\n",
    "    clean_lea = re.sub(r'(Aga(i)?(n)?)\\s+', r'\\1', clean_exp_2)\n",
    "    \n",
    "    return(clean_lea)\n",
    "\n",
    "def process_schoolname(one_name):\n",
    "    \n",
    "    ## uppercase\n",
    "    name_str = str(one_name)\n",
    "    name_upper = name_str.upper()\n",
    "\n",
    "    ## clean up schools\n",
    "    clean_school= re.sub(r'(SCHOO)\\s+', r'\\1', name_upper)\n",
    "    clean_middle = re.sub(r'(MIDD)\\s+', r'\\1', clean_school)\n",
    "    clean_ed = re.sub(r'(EDUCAT)\\s+', r'\\1', clean_middle)\n",
    "    \n",
    "    ## concat whitespace\n",
    "    replace_middle = re.sub(r'M(\\s)?I(\\s)?D(\\s)?D(\\s)?L(\\s)?E', r\"MIDDLE\", clean_ed)\n",
    "    replace_elem = re.sub(r'E(\\s)?L(\\s)?E(\\s)?M(\\s)?E(\\s)?N(\\s)?T(\\s)?A(\\s)?R(\\s)?Y', r\"ELEMENTARY\", replace_middle)\n",
    "    replace_school = re.sub(r'SCHOOI', \"SCHOOL\", replace_elem)\n",
    "    replace_campus = re.sub(r'C(\\s)?A(\\s)?M(\\s)?P(\\s)?U(\\s)?S', r\"CAMPUS\", replace_school)\n",
    "    replace_education = re.sub(r'E(\\s)?D(\\s)?U(\\s)?C(\\s)?A(\\s)?T(\\s)?I(\\s)?O(\\s)?N', r\"EDUCATION\", \n",
    "                               replace_campus)\n",
    "    \n",
    "    ## \n",
    "\n",
    "    return(replace_education)\n",
    "\n",
    "def replace_schooltype(one_string):\n",
    "    \n",
    "    es = re.sub(r'ES$|ELEMENTARY$', r'ELEMENTARY SCHOOL', one_string)\n",
    "    ec = re.sub(r'EC$', r'ELEMENTARY CAMPUS', es)\n",
    "    ms = re.sub(r'MS$|MIDDLE$', r'MIDDLE SCHOOL', ec)\n",
    "    hs = re.sub(r'HS$|HIGH$', r'HIGH SCHOOL', ms)\n",
    "    \n",
    "    return(hs)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def find_fuzzy_namematches(one_name: str, all_names: list, \n",
    "                           score_cutoff):\n",
    "    \n",
    "    ## extract matches above cutoff\n",
    "    all_abovecutoff = process.extractBests(one_name, all_names, score_cutoff = score_cutoff,\n",
    "                                          limit = 1)\n",
    "    \n",
    "    ## make into a dataframe (will thus only capture ones with matches)\n",
    "    all_abovecutoff_df = pd.DataFrame(list(all_abovecutoff), columns = ['matched_name', 'score'])\n",
    "    all_abovecutoff_df['original_name'] = one_name\n",
    "    return(all_abovecutoff_df)\n",
    "\n",
    "## resource-- package installation issues: https://bergvca.github.io/2017/10/14/super-fast-string-matching.html\n",
    "\n",
    "\n",
    "\n",
    "def replace_missing_nces(one_val):\n",
    "    \n",
    "    if one_val.isdigit():\n",
    "        final_val = one_val\n",
    "    else:\n",
    "        final_val = np.nan\n",
    "    return(final_val)\n",
    "\n",
    "def aggregate_crdc(var_col, value_col, \n",
    "                  data,\n",
    "                  id_col = \"school_name\",\n",
    "                  year_chosen = 2013, format = \"long\"):\n",
    "    \n",
    "    \n",
    "    ## shape from long to wide\n",
    "    if(format == \"long\"):\n",
    "        df_wide = pd.pivot_table(data.loc[data.year == year_chosen,\n",
    "                    [id_col,\n",
    "                    var_col, \n",
    "                    value_col]],\n",
    "                    index  = id_col, \n",
    "                    values = value_col,\n",
    "                    columns = var_col).reset_index()\n",
    "\n",
    "    \n",
    "    else:\n",
    "        df_wide = data.loc[data.year == year_chosen].copy()\n",
    "        \n",
    "    ## standardize columns\n",
    "    df_wide.columns = [re.sub(\"\\s+\", \"_\", col.upper()) \n",
    "                           for col in df_wide.columns]\n",
    "        \n",
    "    ## generate rates\n",
    "    sub_cols = set(df_wide.columns).difference([\"SCHOOL_NAME\", \"TOTAL\", 'YEAR'])\n",
    "    \n",
    "    ## \n",
    "    for col in sub_cols:\n",
    "        df_wide[col] = pd.to_numeric(df_wide[col])\n",
    "        df_wide['TOTAL'] = pd.to_numeric(df_wide['TOTAL'])\n",
    "        df_wide['{}_rate'.format(col)] = df_wide[col]/df_wide['TOTAL']\n",
    "    \n",
    "    ## return\n",
    "    return(df_wide)\n",
    "    \n",
    "def aggregate_nces(var_pattern, varname_clean, id_col, \n",
    "                       cc_data_merged,\n",
    "                      enrollment_vars, base_name_raw):\n",
    "    \n",
    "    dem_vars = [col for col in cc_data_merged if var_pattern in col]\n",
    "    long_df = pd.melt(cc_data_merged[dem_vars + enrollment_vars + id_col],\n",
    "                       id_vars = id_col)\n",
    "    \n",
    "    ## create year versus dem col\n",
    "    long_df['clean_value_1'] = [replace_missing_nces(val) for val in long_df.value]\n",
    "    long_df['clean_value'] = pd.to_numeric(long_df.clean_value_1)\n",
    "    long_df['which_var'] = long_df.variable.astype(str).str.replace(\"\\\\_20.*\", \"\")\n",
    "    replace_pattern = \"|\".join(long_df.which_var.unique())\n",
    "    long_df['which_year'] = [re.sub(replace_pattern, \"\", one_var) for one_var in long_df.variable]\n",
    "    long_toagg = long_df[id_col + ['which_var', 'which_year',\n",
    "                                           'clean_value']].reset_index()\n",
    "\n",
    "    ## do the aggregation \n",
    "    index_cols = id_col + [\"which_year\"]\n",
    "    df_wide = long_toagg.pivot_table(index  = index_cols,\n",
    "                                             values = 'clean_value',\n",
    "                                             columns = 'which_var').reset_index()\n",
    "\n",
    "    ## do the division\n",
    "    rate_varname = varname_clean + '_rate'\n",
    "    df_wide[rate_varname] = df_wide[var_pattern]/df_wide[base_name_raw]\n",
    "    #print(df_wide.head())\n",
    "    \n",
    "    ## return cleaned data\n",
    "    return(df_wide[id_col + [rate_varname] + ['which_year']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "base_path = \"/Users/raj2/Dropbox/dph_hearing_decisions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and do prelim cleaning of filings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas_filings_init = pd.read_excel(base_path + \"data/texas/raw_filings/002_dph_20052019_ocr.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Clean years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nan_decision_id</th>\n",
       "      <th>nan_docket_#</th>\n",
       "      <th>reauest_date_o</th>\n",
       "      <th>due_date_decision</th>\n",
       "      <th>date_last_order</th>\n",
       "      <th>date_hearina</th>\n",
       "      <th>nan_lea_student</th>\n",
       "      <th>nan_hearina_officer</th>\n",
       "      <th>(adv./tot.)_issues</th>\n",
       "      <th>nan_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167</td>\n",
       "      <td>057-S E-1105</td>\n",
       "      <td>1905-11-16 00:00:00</td>\n",
       "      <td>1906-01-30 00:00:00</td>\n",
       "      <td>1906-03-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EL PASO ISD (071902)</td>\n",
       "      <td>LARRY CRADDOCK</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>315</td>\n",
       "      <td>132-S E-0206</td>\n",
       "      <td>1906-02-22 00:00:00</td>\n",
       "      <td>1906-05-08 00:00:00</td>\n",
       "      <td>1906-03-06 00:00:00</td>\n",
       "      <td>1906-04-20 00:00:00</td>\n",
       "      <td>EL PASO ISD (071902)</td>\n",
       "      <td>LARRY CRADDOCK</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>325</td>\n",
       "      <td>137-S E-0206</td>\n",
       "      <td>1906-02-27 00:00:00</td>\n",
       "      <td>1906-05-13 00:00:00</td>\n",
       "      <td>1906-02-27 00:00:00</td>\n",
       "      <td>1906-07-17 00:00:00</td>\n",
       "      <td>CLEAR CREEK ISD (084910)</td>\n",
       "      <td>DEBORAH</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCELVANEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>691</td>\n",
       "      <td>273-S E-0806</td>\n",
       "      <td>1906-08-24 00:00:00</td>\n",
       "      <td>1906-11-07 00:00:00</td>\n",
       "      <td>1907-01-29 00:00:00</td>\n",
       "      <td>1906-12-15 00:00:00</td>\n",
       "      <td>RICHARDSON ISD (057916)</td>\n",
       "      <td>STEVEN ALEMAN</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nan_decision_id  nan_docket_#       reauest_date_o    due_date_decision  \\\n",
       "5             167  057-S E-1105  1905-11-16 00:00:00  1906-01-30 00:00:00   \n",
       "6             315  132-S E-0206  1906-02-22 00:00:00  1906-05-08 00:00:00   \n",
       "7             325  137-S E-0206  1906-02-27 00:00:00  1906-05-13 00:00:00   \n",
       "8             NaN           NaN                  NaN                  NaN   \n",
       "9             691  273-S E-0806  1906-08-24 00:00:00  1906-11-07 00:00:00   \n",
       "\n",
       "       date_last_order         date_hearina           nan_lea_student  \\\n",
       "5  1906-03-06 00:00:00                  NaN      EL PASO ISD (071902)   \n",
       "6  1906-03-06 00:00:00  1906-04-20 00:00:00      EL PASO ISD (071902)   \n",
       "7  1906-02-27 00:00:00  1906-07-17 00:00:00  CLEAR CREEK ISD (084910)   \n",
       "8                  NaN                  NaN                       NaN   \n",
       "9  1907-01-29 00:00:00  1906-12-15 00:00:00   RICHARDSON ISD (057916)   \n",
       "\n",
       "  nan_hearina_officer (adv./tot.)_issues nan_nan  \n",
       "5      LARRY CRADDOCK                0/0     NaN  \n",
       "6      LARRY CRADDOCK                0/0     NaN  \n",
       "7             DEBORAH                0/0     NaN  \n",
       "8           MCELVANEY                NaN     NaN  \n",
       "9       STEVEN ALEMAN                0/0     NaN  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\nRemoving the blank rows takes the data from 6093 rows to 4026 rows.\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combine 2nd and 3rd row into columns\n",
    "name_cols_init = [\"{}_{}\".format(b_, a_) for a_, b_ in zip(texas_filings_init.iloc[2, ], \n",
    "                                                     texas_filings_init.iloc[3, ])]\n",
    "\n",
    "name_cols = [re.sub(\"\\s+\", \"_\", col.lower()) for col in name_cols_init]\n",
    "\n",
    "## create df and rename cols\n",
    "##\n",
    "texas_filings_init_df = texas_filings_init.iloc[5:, ].copy()\n",
    "texas_filings_init_df.columns = name_cols\n",
    "texas_filings_init_df.head()\n",
    "\n",
    "## see from pdf that blank rows\n",
    "## are ones where hearing officer splits onto\n",
    "## second line\n",
    "## remove ones with nan for decision id\n",
    "non_ids = \"|\".join([\"ID\", \"Decision\", \"Page\",\n",
    "                   \"DISMISSED\", \"GRANTED\", \"DENIED\", \"AM\", \"PM\",\n",
    "                   \"PENDING\"])\n",
    "texas_filings_real = texas_filings_init_df.loc[(texas_filings_init_df.nan_decision_id.notnull()) &\n",
    "                                (~texas_filings_init_df.nan_decision_id.astype(str).str.contains(non_ids)),\n",
    "                                              ].copy()\n",
    "\n",
    "\"\"\"\n",
    "Removing the blank rows takes the data from {} rows to {} rows.\n",
    "\"\"\".format(texas_filings_init_df.shape[0],\n",
    "          texas_filings_real.shape[0])\n",
    "\n",
    "\n",
    "## see that years are 100 below but dates are correct\n",
    "## so just extract year\n",
    "year_request = [str(one_request.year + 100) for one_request in pd.to_datetime(texas_filings_real.reauest_date_o,\n",
    "                            format = \"%Y-%m-%d 00:00:00\", errors = \"coerce\")]\n",
    "\n",
    "texas_filings_real['year_request'] = year_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Extract state-level school identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "isds = [re.sub(r'.*\\(([0-9]+)\\).*', r'\\1', one_string) if type(one_string) == str\n",
    "        else np.nan\n",
    "        for one_string in texas_filings_real.nan_lea_student]\n",
    "\n",
    "texas_filings_real['isd_init'] = isds\n",
    "texas_filings_real['failed_extract_isd'] = np.where(texas_filings_real.isd_init.astype(str).str.len() != 6, \n",
    "                                                    1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate into ones with isd, ones without\n",
    "texas_wisd = texas_filings_real.loc[texas_filings_real.failed_extract_isd == 0].copy()\n",
    "texas_noisd = texas_filings_real.loc[texas_filings_real.failed_extract_isd == 1].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 Issue one: present but in earlier col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    759\n",
       "1    194\n",
       "Name: failed_extract_isd, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for those with no isd, try to extract from earlier col\n",
    "isds_earlier = [re.sub(r'.*\\(([0-9]+)\\).*', r'\\1', one_string) if type(one_string) == str\n",
    "        else np.nan\n",
    "        for one_string in texas_noisd.date_hearina]\n",
    "\n",
    "texas_noisd_new = texas_noisd.drop(columns = ['isd_init', 'failed_extract_isd'], inplace = False)\n",
    "texas_noisd_new['isd_init'] = isds_earlier\n",
    "texas_noisd_new['failed_extract_isd'] = np.where(texas_noisd_new.isd_init.astype(str).str.len() != 6, \n",
    "                                                    1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3832\n",
       "1     194\n",
       "Name: failed_extract_isd, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    3073\n",
       "1     953\n",
       "Name: failed_extract_isd, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texas_round2 = pd.concat([texas_wisd, texas_noisd_new], axis = 0)\n",
    "texas_round2.failed_extract_isd.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Issue two-- moved on to next row because name too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-101809'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'101809'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get decision ids of the ones still missing\n",
    "decision_ids_missisd = texas_round2.nan_decision_id[texas_round2.failed_extract_isd == 1].copy()\n",
    "\n",
    "## in original data, get row indices of those ids\n",
    "rows_missisd = texas_filings_init_df[texas_filings_init_df.nan_decision_id.isin(decision_ids_missisd)].index.tolist()\n",
    "nextrow_missisd = [row_num + 1 for row_num in rows_missisd]\n",
    "\n",
    "df_nextrow_missisd = texas_filings_init_df.loc[texas_filings_init_df.index.isin(nextrow_missisd), ].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000    3832\n",
       "Name: failed_extract_isd, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'There are 497 unique isds in filings data.\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_next_row(one_row):\n",
    "    \n",
    "    ## convert to correct type\n",
    "    if type(one_row) != str:\n",
    "        clean_row = str(one_row)\n",
    "    else:\n",
    "        clean_row = one_row\n",
    "        \n",
    "    ## extract correct pattern    \n",
    "    if bool(re.search(r'^-', str(clean_row))) == True:\n",
    "        isd = re.sub(r'^-', '', str(clean_row))\n",
    "    \n",
    "    elif bool(re.search(r'\\(', clean_row)) == True:\n",
    "        isd = re.sub(r'.*\\(([0-9]+)\\).*', r'\\1', clean_row)\n",
    "        \n",
    "    else:\n",
    "        isd = np.nan\n",
    "        \n",
    "    ## pad 0's\n",
    "    if type(isd) == str and len(isd) == 5:\n",
    "        isd = \"0\" + isd\n",
    "        \n",
    "    return(isd)\n",
    "\n",
    "\n",
    "nextrow_isds = [clean_next_row(one_row) for one_row in df_nextrow_missisd.nan_lea_student]\n",
    "\n",
    "## add to original\n",
    "texas_round2_noisd = texas_round2[texas_round2.failed_extract_isd == 1].copy().drop(columns = [\"isd_init\",\n",
    "                                                                                              'failed_extract_isd'])\n",
    "texas_round2_noisd['isd_init'] = nextrow_isds\n",
    "texas_noisd_new['failed_extract_isd'] = np.where(texas_noisd_new.isd_init.astype(str).str.len() != 6, \n",
    "                                                    1, 0)\n",
    "\n",
    "## rowbind\n",
    "texas_round3 = pd.concat([texas_round2[texas_round2.failed_extract_isd == 0].copy(),\n",
    "                         texas_round2_noisd], axis = 0)\n",
    "\n",
    "\n",
    "\"\"\"There are {} unique isds in filings data.\n",
    "\"\"\".format(len(texas_round3.isd_init.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge with nces crosswalk'\n",
    "\n",
    "Next steps-- look at overlap\n",
    "Troubleshoot non-overlap\n",
    "Merge with crosswalk then with nces district-level demographics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## load nces data for texas \n",
    "## and before working on further, \n",
    "## see if the ids are useful\n",
    "## before cleaning further\n",
    "id_crosswalk = pd.read_csv(base_path + \"data/texas/intermediate/texas_distid_nces_crosswalk.csv\")\n",
    "id_crosswalk['statelevel_id'] = [str(re.sub(\"-\", \"\", one_id)) for one_id in id_crosswalk.DISTRICT]\n",
    "id_crosswalk_relcols = id_crosswalk[['statelevel_id', 'NCES_DISTR']].copy()\n",
    "\n",
    "## \n",
    "texas_ids_unique = id_crosswalk_relcols.statelevel_id.unique()\n",
    "filings_ids_unique = set(isds)\n",
    "len(filings_ids_unique)\n",
    "\n",
    "\n",
    "## see from pdf that dates are generally correct\n",
    "## but 100 years to early\n",
    "## use request date\n",
    "texas_filings_real['request_date_final'] = pd.to_datetime(texas_filings_real.reauest_date_o) + relativedelta(years = 100)\n",
    "texas_filings_real.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. older code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After removing those that failed to parse, go from 7949 filings to 7752 filings.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_filings_init = pd.read_csv(base_path + \"data/dc/intermediate/processed_filings.csv\")\n",
    "\n",
    "dc_filings_init['failed_parse'] = np.where(dc_filings_init.eq(dc_filings_init.iloc[:, 0], \n",
    "                                axis=0).all(1), 1, 0)\n",
    "\n",
    "\n",
    "## get row number of those that failed parse to reprocess\n",
    "rownums_failedparse = pd.DataFrame({'missing_info':\n",
    "                dc_filings_init.loc[dc_filings_init.failed_parse == 1].index.tolist()})\n",
    "\n",
    "## write those and go back to process tables, pulling all cols for those rows\n",
    "rownums_failedparse.to_pickle(base_path + \"data/dc/intermediate/rownums_failedparse.pickle\")\n",
    "\n",
    "\n",
    "## subset to ones that parsed\n",
    "dc_filings = dc_filings_init.loc[dc_filings_init.failed_parse == 0, ].copy()\n",
    "\n",
    "\"\"\"After removing those that failed to parse, go from {} filings to {} filings.\n",
    "\"\"\".format(dc_filings_init.shape[0],\n",
    "          dc_filings.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012              1651\n",
       "2013              1459\n",
       "2014              1023\n",
       "2015              1001\n",
       "2018               834\n",
       "2017               702\n",
       "2016               626\n",
       "2019               269\n",
       "failed_toparse     187\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_filings['casetype_clean_init'] = [process_type(one_type) for one_type in dc_filings.casetype.tolist()]\n",
    "dc_filings['casetype_isdigits'] = [\"digits\" if re.match(r'[0-9]+', one_str) is not None  else \"no_digits\" \n",
    "        for one_str in dc_filings.casetype_clean_init]\n",
    "\n",
    "## by subsetting to those, see that year is still in the case so don't need to use for that\n",
    "dc_filings['casetype_final'] = np.where((dc_filings.casetype_clean_init.str.contains(\"Discip\")) |\n",
    "                                        (dc_filings.casetype_clean_init.str.contains(\"Expedited\")),\n",
    "                                        \"Expedited Discipline\",\n",
    "                                np.where((dc_filings.casetype_clean_init.str.contains(\"LEA\")) & \n",
    "                                         (dc_filings.casetype_clean_init != \"By LEA\"), \"Against LEA\",\n",
    "                                np.where(dc_filings.casetype_clean_init == \"By LEA\", \"By LEA\",\n",
    "                                np.where(dc_filings.casetype_clean_init.str.contains(\"Against SE\"),\n",
    "                                        \"Against SEA\",\n",
    "                                        \"Other/failed to parse\"))))\n",
    "\n",
    "\n",
    "## write the failed to parse ones\n",
    "## write those and go back to process tables, pulling the rows manually\n",
    "dc_filings[dc_filings.casetype_final == \"Other/failed to parse\"].to_csv(base_path + \"data/dc/intermediate/missing_casetype.csv\")\n",
    "\n",
    "\n",
    "## get range of dates of the filings\n",
    "dc_filings['year_init'] = [re.sub(r'^(20[1-2][0-9]).*', r'\\1', str(one_string)) for one_string in \n",
    "                      dc_filings.case_no]\n",
    "year_range = [str(i) for i in np.arange(2012, 2020).tolist()]\n",
    "dc_filings['year'] = np.where(dc_filings.year_init.isin(year_range), dc_filings.year_init,\n",
    "                             'failed_toparse')\n",
    "dc_filings.year.value_counts() # half the year in 2019\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge in district demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create name-nces ID crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 75-col limit in export-- first 75 cols\n",
    "cc_data_1 = pd.read_csv(base_path + \"data/dc/intermediate/dc_ccd.csv\")\n",
    "\n",
    "## \n",
    "cc_data_2 = pd.read_csv(base_path + \"data/dc/intermediate/dc_ccd_pull2.csv\",\n",
    "                       encoding= 'unicode_escape')\n",
    "\n",
    "## find overlapping cols\n",
    "cc_data_1_topull = cc_data_1.columns.difference(cc_data_2.columns).tolist() + \\\n",
    "                    [\"School Name\", \n",
    "                     \"School ID - NCES Assigned [Public School] Latest available year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge excluding\n",
    "cc_data_merged = pd.merge(cc_data_1[cc_data_1_topull], \n",
    "                          cc_data_2, \n",
    "                          on = \"School Name\",\n",
    "                         how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGENCY_ID_-_NCES_ASSIGNED__PUBLIC_SCHOOL__LATEST_AVAILABLE_YEAR',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2012-13',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2013-14',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2014-15',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2015-16',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2016-17',\n",
      "       'AGENCY_NAME__PUBLIC_SCHOOL__2017-18',\n",
      "       'DIRECT_CERTIFICATION__PUBLIC_SCHOOL__2016-17',\n",
      "       'DIRECT_CERTIFICATION__PUBLIC_SCHOOL__2017-18',\n",
      "       'FREE_LUNCH_ELIGIBLE__PUBLIC_SCHOOL__2012-13',\n",
      "       ...\n",
      "       'PUPIL/TEACHER_RATIO__PUBLIC_SCHOOL__2015-16',\n",
      "       'PUPIL/TEACHER_RATIO__PUBLIC_SCHOOL__2014-15',\n",
      "       'PUPIL/TEACHER_RATIO__PUBLIC_SCHOOL__2013-14',\n",
      "       'PUPIL/TEACHER_RATIO__PUBLIC_SCHOOL__2012-13',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2017-18',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2016-17',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2015-16',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2014-15',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2013-14',\n",
      "       'FULL-TIME_EQUIVALENT__FTE__TEACHERS__PUBLIC_SCHOOL__2012-13'],\n",
      "      dtype='object', length=133)\n"
     ]
    }
   ],
   "source": [
    "cc_cleancols = [re.sub(\"\\\\s+|\\\\[|\\\\]|\\\\(|\\\\)\", \"_\", x).upper() for x in cc_data_merged.columns]\n",
    "cc_data_merged.columns = cc_cleancols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## create crosswalk to do matching\n",
    "cc_crosswalk = cc_data_merged[['SCHOOL_NAME', \n",
    "                        'AGENCY_ID_-_NCES_ASSIGNED__PUBLIC_SCHOOL__LATEST_AVAILABLE_YEAR']].copy().drop_duplicates()\n",
    "\n",
    "\n",
    "cc_crosswalk['name_tocompare'] = [replace_schooltype(one_school) for one_school in cc_crosswalk.SCHOOL_NAME]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clean school name and fuzzy matching to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess school to clean\n",
    "## and do fuzzy matching\n",
    "dc_filings_tomatch = dc_filings[['case_no', 'dcps_school_against', 'year', 'casetype_final']].drop_duplicates(subset = \n",
    "                                                ['case_no',\n",
    "                                                'dcps_school_against'])\n",
    "\n",
    "\n",
    "\n",
    "dc_filings_tomatch['school_against_cleaned_1'] = [process_schoolname(one_name) \n",
    "                                                for one_name in dc_filings_tomatch.dcps_school_against]\n",
    "dc_filings_tomatch['school_against_cleaned'] = [replace_schooltype(one_name)\n",
    "                                               for one_name in dc_filings_tomatch.school_against_cleaned_1]\n",
    "\n",
    "\n",
    "\n",
    "## generate tf-idf representation\n",
    "filings_crosswalk = dc_filings_tomatch[['school_against_cleaned']].drop_duplicates()\n",
    "filings_crosswalk['id'] = filings_crosswalk.index+1\n",
    "\n",
    "\n",
    "## write to intermediate\n",
    "cc_crosswalk.to_csv(base_path + \"data/dc/intermediate/nces_schoolnames.csv\")\n",
    "filings_crosswalk.to_csv(base_path + \"data/dc/intermediate/filings_names.csv\")\n",
    "\n",
    "\n",
    "id_rename_dict = {'AGENCY_ID_-_NCES_ASSIGNED__PUBLIC_SCHOOL__LATEST_AVAILABLE_YEAR': \n",
    "                      'nces_id'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_against_cleaned</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEIGHTS EDUCATION CENTER HIGH SCHOOL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 school_against_cleaned  id\n",
       "0                                   NAN   1\n",
       "1                           PROSPECT LC   2\n",
       "5  HEIGHTS EDUCATION CENTER HIGH SCHOOL   6\n",
       "7                 JOHNSON MIDDLE SCHOOL   8\n",
       "9                   EASTERN HIGH SCHOOL  10"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ran script: 03helper_fuzzymatch_nces.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 merge in fuzzy match results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "0    109\n",
       "Name: matched_manually, dtype: int64"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load results of fmatch\n",
    "fm_cc_filings = pd.read_csv(base_path + \"data/dc/intermediate/nces_filings_fuzzymatch.csv\")\n",
    "\n",
    "\n",
    "\n",
    "## merge back using original name\n",
    "filings_crosswalk_wmatch = pd.merge(filings_crosswalk, \n",
    "                                   fm_cc_filings[['original_name', 'matched_name', 'score']],\n",
    "                                   left_on = 'school_against_cleaned',\n",
    "                                   right_on = 'original_name',\n",
    "                                   how = \"left\")\n",
    "\n",
    "filings_crosswalk_wmatch['matched'] = np.where(filings_crosswalk_wmatch.score.notnull(), 1, 0)\n",
    "\n",
    "## write the non-matched ones to csv and deal with later\n",
    "## filtered out \"other\" and \"non-attending\"\n",
    "filings_crosswalk_wmatch.loc[filings_crosswalk_wmatch.matched == 0].to_csv(base_path + \"data/dc/intermediate/nonmatch_schoolname.csv\")\n",
    "\n",
    "## manually matched them \n",
    "\n",
    "manualmatch = pd.read_csv(base_path + \"data/dc/intermediate/manual_nonmatch_dc.csv\")\n",
    "manualmatch['matched_manually'] = np.where(manualmatch.matched_name.notnull(), 1, 0)\n",
    "manualmatch.matched_manually.value_counts()\n",
    "\n",
    "manualmatch_ccd = manualmatch.loc[(manualmatch.source == \"ccd\") & \n",
    "                                 (manualmatch.multiple == 0) & \n",
    "                                 (manualmatch.matched_manually == 1)].copy().drop_duplicates() # filters out \n",
    "                                    # ones that matched to crdc and multi-campus pcs\n",
    "manualmatch_ccd['score'] = np.nan\n",
    "\n",
    "## merge with filings \n",
    "filings_crosswalk_wmanualmatch = pd.merge(filings_crosswalk, \n",
    "                                   manualmatch_ccd,\n",
    "                                   left_on = 'school_against_cleaned',\n",
    "                                   right_on = 'original_name',\n",
    "                                   how = \"left\")\n",
    "\n",
    "filings_crosswalk_wmanualmatch['matched_manually'] = np.where(filings_crosswalk_wmanualmatch.matched_name.notnull(),\n",
    "                                        1, 0)\n",
    "\n",
    "filings_crosswalk_wmanualmatch_matched = filings_crosswalk_wmanualmatch.loc[filings_crosswalk_wmanualmatch.matched_manually == 1].copy()\n",
    "\n",
    "\n",
    "## rowbind into one crosswalk\n",
    "filings_crosswalk_fuzzy_matched = filings_crosswalk_wmatch.loc[filings_crosswalk_wmatch.matched == 1].copy()\n",
    "\n",
    "## Combined crosswalk\n",
    "filings_crosswalk_both = pd.concat([filings_crosswalk_fuzzy_matched[['school_against_cleaned',\n",
    "                                                                    'original_name',\n",
    "                                                                    'matched_name','score']],\n",
    "                                   filings_crosswalk_wmanualmatch_matched[['school_against_cleaned',\n",
    "                                                                    'original_name',\n",
    "                                                                    'matched_name','score']]])\n",
    "\n",
    "filings_crosswalk_both['type_match'] = np.where(filings_crosswalk_both.score.notnull(),\n",
    "                                               \"fuzzy\",\n",
    "                                               \"manual\")\n",
    "\n",
    "\n",
    "## write filings not in crosswalk\n",
    "filings_crosswalk_notmatched = filings_crosswalk.loc[~filings_crosswalk.school_against_cleaned.isin(fm_cc_filings.original_name.tolist() +\n",
    "                            manualmatch.original_name[manualmatch.matched_manually == 1].tolist())].copy()\n",
    "\n",
    "#print(filings_crosswalk_notmatched[['school_against_cleaned']].sort_values(by = \n",
    " #                                       \"school_against_cleaned\").to_latex(index = False))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_against_cleaned</th>\n",
       "      <th>original_name</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>score</th>\n",
       "      <th>type_match</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>AGENCY_ID_-_NCES_ASSIGNED__PUBLIC_SCHOOL__LATEST_AVAILABLE_YEAR</th>\n",
       "      <th>name_tocompare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>100.000</td>\n",
       "      <td>fuzzy</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>1100030.000</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>100.000</td>\n",
       "      <td>fuzzy</td>\n",
       "      <td>JOHNSON MS</td>\n",
       "      <td>1100030.000</td>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>100.000</td>\n",
       "      <td>fuzzy</td>\n",
       "      <td>EASTERN HS</td>\n",
       "      <td>1100030.000</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASTE RN HIGH SCHOOL</td>\n",
       "      <td>EASTE RN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>97.000</td>\n",
       "      <td>fuzzy</td>\n",
       "      <td>EASTERN HS</td>\n",
       "      <td>1100030.000</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "      <td>100.000</td>\n",
       "      <td>fuzzy</td>\n",
       "      <td>DUNBAR HS</td>\n",
       "      <td>1100030.000</td>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_against_cleaned          original_name           matched_name  \\\n",
       "0            PROSPECT LC            PROSPECT LC            PROSPECT LC   \n",
       "1  JOHNSON MIDDLE SCHOOL  JOHNSON MIDDLE SCHOOL  JOHNSON MIDDLE SCHOOL   \n",
       "2    EASTERN HIGH SCHOOL    EASTERN HIGH SCHOOL    EASTERN HIGH SCHOOL   \n",
       "3   EASTE RN HIGH SCHOOL   EASTE RN HIGH SCHOOL    EASTERN HIGH SCHOOL   \n",
       "4     DUNBAR HIGH SCHOOL     DUNBAR HIGH SCHOOL     DUNBAR HIGH SCHOOL   \n",
       "\n",
       "    score type_match  SCHOOL_NAME  \\\n",
       "0 100.000      fuzzy  PROSPECT LC   \n",
       "1 100.000      fuzzy   JOHNSON MS   \n",
       "2 100.000      fuzzy   EASTERN HS   \n",
       "3  97.000      fuzzy   EASTERN HS   \n",
       "4 100.000      fuzzy    DUNBAR HS   \n",
       "\n",
       "   AGENCY_ID_-_NCES_ASSIGNED__PUBLIC_SCHOOL__LATEST_AVAILABLE_YEAR  \\\n",
       "0                                        1100030.000                 \n",
       "1                                        1100030.000                 \n",
       "2                                        1100030.000                 \n",
       "3                                        1100030.000                 \n",
       "4                                        1100030.000                 \n",
       "\n",
       "          name_tocompare  \n",
       "0            PROSPECT LC  \n",
       "1  JOHNSON MIDDLE SCHOOL  \n",
       "2    EASTERN HIGH SCHOOL  \n",
       "3    EASTERN HIGH SCHOOL  \n",
       "4     DUNBAR HIGH SCHOOL  "
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## merge in nces ID based on matched name\n",
    "filings_crosswalk_wid = pd.merge(filings_crosswalk_both,\n",
    "                                cc_crosswalk,\n",
    "                                 left_on = 'matched_name',\n",
    "                                 right_on = 'name_tocompare',\n",
    "                                 how = \"left\").drop_duplicates()\n",
    "\n",
    "filings_crosswalk_wid.head()\n",
    "filings_crosswalk_wid.rename(columns = id_rename_dict, inplace = True)\n",
    "filings_crosswalk_tomerge = filings_crosswalk_wid[['nces_id', 'school_against_cleaned',\n",
    "                                                  'name_tocompare', \n",
    "                                                  'SCHOOL_NAME']].copy()\n",
    "filings_crosswalk_tomerge.rename(columns = {'SCHOOL_NAME': 'nces_name'},\n",
    "                                inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nces_id</th>\n",
       "      <th>school_against_cleaned</th>\n",
       "      <th>name_tocompare</th>\n",
       "      <th>nces_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100030.000</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "      <td>PROSPECT LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100030.000</td>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>JOHNSON MIDDLE SCHOOL</td>\n",
       "      <td>JOHNSON MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100030.000</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100030.000</td>\n",
       "      <td>EASTE RN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HIGH SCHOOL</td>\n",
       "      <td>EASTERN HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100030.000</td>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "      <td>DUNBAR HIGH SCHOOL</td>\n",
       "      <td>DUNBAR HS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nces_id school_against_cleaned         name_tocompare    nces_name\n",
       "0 1100030.000            PROSPECT LC            PROSPECT LC  PROSPECT LC\n",
       "1 1100030.000  JOHNSON MIDDLE SCHOOL  JOHNSON MIDDLE SCHOOL   JOHNSON MS\n",
       "2 1100030.000    EASTERN HIGH SCHOOL    EASTERN HIGH SCHOOL   EASTERN HS\n",
       "3 1100030.000   EASTE RN HIGH SCHOOL    EASTERN HIGH SCHOOL   EASTERN HS\n",
       "4 1100030.000     DUNBAR HIGH SCHOOL     DUNBAR HIGH SCHOOL    DUNBAR HS"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filings_crosswalk_tomerge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 merge with main case file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7295 entries, 0 to 7294\n",
      "Data columns (total 8 columns):\n",
      "case_no                   7293 non-null object\n",
      "dcps_school_against       7294 non-null object\n",
      "year                      7295 non-null object\n",
      "school_against_cleaned    7295 non-null object\n",
      "casetype_final            7295 non-null object\n",
      "nces_id                   6258 non-null float64\n",
      "name_tocompare            6258 non-null object\n",
      "nces_name                 6258 non-null object\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 512.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Of the 7295 unique school names in filings, 6258, or 0.8578478409869774 proportion, were matched with an NCES ID\\n'"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge back on to main data\n",
    "\n",
    "dc_filings_wid = pd.merge(dc_filings_tomatch[['case_no',\n",
    "                                             'dcps_school_against',\n",
    "                                             'year',\n",
    "                                             'school_against_cleaned',\n",
    "                                             'casetype_final']],\n",
    "                         filings_crosswalk_tomerge,\n",
    "                         on = 'school_against_cleaned',\n",
    "                         how = 'left')\n",
    "dc_filings_wid.info()\n",
    "\n",
    "## only able to match 60% to an nces id; seems most important troubleshooting is \n",
    "## improving crosswalk\n",
    "dc_filings_wid['caseid_stripyear'] = dc_filings_wid.case_no.replace(r'20[1-9][0-9]\\-(\\-)?', '', regex = True)\n",
    "dc_filings_wid['caseid_firstfiled'] = dc_filings_wid.caseid_stripyear.replace(r'\\-(-)?.*', '', regex = True)\n",
    "dc_filings_wid['caseid'] = dc_filings_wid.caseid_firstfiled.str.replace(' ', '')\n",
    "dc_filings_wid_obsid = dc_filings_wid.loc[dc_filings_wid.nces_name.notnull()].copy()\n",
    "\n",
    "# 86% match (still need to do multiple match ones etc)\n",
    "\n",
    "n_original = dc_filings_wid.shape[0]\n",
    "n_matched = dc_filings_wid_obsid.shape[0]\n",
    "\n",
    "\"\"\"Of the {} unique school names in filings, {}, or {} proportion, were matched with an NCES ID\n",
    "\"\"\".format(n_original, \n",
    "          n_matched,\n",
    "          n_matched/n_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove missing and aggregate\n",
    "dc_filings_valid = dc_filings_wid_obsid[['nces_id',\n",
    "                                'caseid',\n",
    "                                 'year',\n",
    "                                'nces_name',\n",
    "                                'casetype_final']].drop_duplicates()\n",
    "\n",
    "dc_filings_valid['id_foragg'] = dc_filings_valid.caseid + dc_filings_valid.year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-652-e498cf7f7c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc_filings_totalbyschool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'head' is not defined"
     ]
    }
   ],
   "source": [
    "dc_filings_totalbyschool = dc_filings_valid.groupby(['nces_name',\n",
    "                                                    'casetype_final', \n",
    "                                                    'year'])['id_foragg'].nunique().reset_index().sort_values(by =\n",
    "                    'nces_name')\n",
    "\n",
    "dc_filings_totalbyschool.rename(columns = {'id_foragg': 'count_filings'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: common core data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            ACADEMY OF HOPE ADULT PCS\n",
       "1               ACHIEVEMENT PREPARATORY PCS ELEMENTARY\n",
       "2            ACHIEVEMENT PREPARATORY PCS MIDDLE SCHOOL\n",
       "3    ADAMS ELEMENTARY SCHOOL                       ...\n",
       "4                                ADVANCED PATH ACADEMY\n",
       "Name: SCHOOL_NAME, dtype: object"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "enrollment_vars = [col for col in cc_data_merged if 'TOTAL_STUDENTS' in col]\n",
    "base_name_raw = 'TOTAL_STUDENTS_ALL_GRADES__EXCLUDES_AE___PUBLIC_SCHOOL_'\n",
    "\n",
    "id_col = \"SCHOOL_NAME\"\n",
    "\n",
    "cc_data_merged.SCHOOL_NAME.head()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "frpl_rate = aggregate_nces(var_pattern = \"FREE_LUNCH_ELIGIBLE__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"frpl_eligible\",\n",
    "                          id_col = ['SCHOOL_NAME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>which_var</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>frpl_eligible_rate</th>\n",
       "      <th>which_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>YOUTHBUILD PCS</td>\n",
       "      <td>0.964</td>\n",
       "      <td>_2013-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>YOUTHBUILD PCS</td>\n",
       "      <td>0.780</td>\n",
       "      <td>_2014-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>YOUTHBUILD PCS</td>\n",
       "      <td>0.377</td>\n",
       "      <td>_2015-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>YOUTHBUILD PCS</td>\n",
       "      <td>nan</td>\n",
       "      <td>_2016-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>YOUTHBUILD PCS</td>\n",
       "      <td>nan</td>\n",
       "      <td>_2017-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "which_var     SCHOOL_NAME  frpl_eligible_rate which_year\n",
       "1741       YOUTHBUILD PCS               0.964   _2013-14\n",
       "1742       YOUTHBUILD PCS               0.780   _2014-15\n",
       "1743       YOUTHBUILD PCS               0.377   _2015-16\n",
       "1744       YOUTHBUILD PCS                 nan   _2016-17\n",
       "1745       YOUTHBUILD PCS                 nan   _2017-18"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_enrollment_vars = [col for col in cc_data_merged.columns if \"TOTAL_RACE\" in col]\n",
    "black_rate = aggregate_nces(var_pattern = \"BLACK_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"black\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                           id_col = ['SCHOOL_NAME'])\n",
    "white_rate = aggregate_nces(var_pattern = \"WHITE_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"white\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                           id_col = ['SCHOOL_NAME'])\n",
    "hisp_rate = aggregate_nces(var_pattern = \"HISPANIC_STUDENTS__PUBLIC_SCHOOL_\",\n",
    "                              varname_clean = \"hispanic\",\n",
    "                               enrollment_vars = race_enrollment_vars,\n",
    "                               base_name_raw = \"TOTAL_RACE/ETHNICITY__PUBLIC_SCHOOL_\",\n",
    "                          id_col = ['SCHOOL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1746 entries, 0 to 1745\n",
      "Data columns (total 6 columns):\n",
      "nces_name             1746 non-null object\n",
      "which_year            1746 non-null object\n",
      "frpl_eligible_rate    1124 non-null float64\n",
      "black_rate            1090 non-null float64\n",
      "white_rate            1014 non-null float64\n",
      "hispanic_rate         1085 non-null float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 81.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## merge into one df\n",
    "\n",
    "dfs = [df.set_index(['SCHOOL_NAME', \n",
    "                     'which_year']) for df in [frpl_rate, black_rate, white_rate, hisp_rate]]\n",
    "\n",
    "cc_dem_rates = pd.concat(dfs, axis=1).reset_index()\n",
    "cc_dem_rates.rename(columns = {'SCHOOL_NAME': \n",
    "                      'nces_name'}, inplace = True)\n",
    "\n",
    "\n",
    "## use demographics at baseline-ish\n",
    "## maybe exclude 2012\n",
    "\n",
    "## for each id, could how \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CCD data on ieps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in iep data \n",
    "crdc = pd.read_csv(base_path + \"data/dc/intermediate/EducationDataPortal_03.07.2020_disability.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate\n",
    "iep_summary = aggregate_crdc(var_col = \"disability\", \n",
    "                            value_col = \"enrollment_crdc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read and clean discipline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'ncessch', 'school_name', 'state_name', 'lea_name',\n",
       "       'school_level', 'school_type', 'charter', 'free_lunch',\n",
       "       'reduced_price_lunch', 'free_or_reduced_price_lunch', 'enrollment',\n",
       "       'direct_certification', 'enrollment_crdc', 'students_susp_in_sch',\n",
       "       'students_susp_out_sch_single', 'students_susp_out_sch_multiple',\n",
       "       'expulsions_no_ed_serv', 'expulsions_with_ed_serv',\n",
       "       'expulsions_zero_tolerance', 'students_corporal_punish',\n",
       "       'students_arrested', 'students_referred_law_enforce',\n",
       "       'students_mech_restraint', 'students_phys_restraint',\n",
       "       'students_seclusion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crdc_largerpull = pd.read_csv(base_path + \"data/dc/intermediate/EducationDataPortal_03.08.2020_schools.csv\")\n",
    "\n",
    "\n",
    "## fill NA with 0\n",
    "crdc_largerpull_fill = crdc_largerpull.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "## discipline\n",
    "discipline_cols = [col for col in crdc_largerpull_fill.columns if \n",
    "                  \"susp\" in col or \"expulsions\" in col or \"corporal\" in col]\n",
    "restr_secl_cols = [col for col in crdc_largerpull_fill.columns if \n",
    "                  \"restraint\" in col or \"seclusion\" in col]\n",
    "\n",
    "crdc_largerpull_fill['total_discipline'] = crdc_largerpull_fill[discipline_cols].sum(axis = 1)\n",
    "crdc_largerpull_fill['total_restraint_seclude'] = crdc_largerpull_fill[restr_secl_cols].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>year</th>\n",
       "      <th>total</th>\n",
       "      <th>total_discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cesar Chavez PCS for Public Policy Capitol Hill</td>\n",
       "      <td>2016</td>\n",
       "      <td>332</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cesar Chavez PCS for Public Policy Parkside Mi...</td>\n",
       "      <td>2016</td>\n",
       "      <td>278</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cesar Chavez PCS for Public Policy Chavez Prep</td>\n",
       "      <td>2016</td>\n",
       "      <td>306</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cesar Chavez PCS for Public Policy Parkside High</td>\n",
       "      <td>2016</td>\n",
       "      <td>359</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friendship PCS Collegiate Academy</td>\n",
       "      <td>2016</td>\n",
       "      <td>751</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         school_name  year total  \\\n",
       "0    Cesar Chavez PCS for Public Policy Capitol Hill  2016   332   \n",
       "1  Cesar Chavez PCS for Public Policy Parkside Mi...  2016   278   \n",
       "2     Cesar Chavez PCS for Public Policy Chavez Prep  2016   306   \n",
       "3   Cesar Chavez PCS for Public Policy Parkside High  2016   359   \n",
       "4                  Friendship PCS Collegiate Academy  2016   751   \n",
       "\n",
       "   total_discipline  \n",
       "0             0.000  \n",
       "1             0.000  \n",
       "2             0.000  \n",
       "3             0.000  \n",
       "4             0.000  "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crdc_disc_foragg = crdc_largerpull_fill.loc[~crdc_largerpull_fill.enrollment.isin(['0',\n",
    "                                        'Not applicable']),\n",
    "                                        ['school_name', 'year',\n",
    "                                        'enrollment',\n",
    "                                        'total_discipline']].copy()\n",
    "crdc_disc_foragg.rename(columns = {'enrollment':\n",
    "            'total'}, inplace = True)\n",
    "\n",
    "crdc_disc_foragg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>ARTS AND TECHNOLOGY PCS</td>\n",
       "      <td>2013</td>\n",
       "      <td>618</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>BOOKER T  WASHINGTON PCS</td>\n",
       "      <td>2013</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>CESAR CHAVEZ FOR PUBLIC POLICY CAPITOL HILL PCS</td>\n",
       "      <td>2013</td>\n",
       "      <td>389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>CESAR CHAVEZ PCS FOR PUBLIC POLICY-PARKSIDE HS</td>\n",
       "      <td>2013</td>\n",
       "      <td>305</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>CESAR CHAVEZ PCS FOR PUBLIC POLICY CHAVEZ PREP</td>\n",
       "      <td>2013</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         SCHOOL_NAME  YEAR  TOTAL  \\\n",
       "751                          ARTS AND TECHNOLOGY PCS  2013    618   \n",
       "752                         BOOKER T  WASHINGTON PCS  2013    177   \n",
       "754  CESAR CHAVEZ FOR PUBLIC POLICY CAPITOL HILL PCS  2013    389   \n",
       "755   CESAR CHAVEZ PCS FOR PUBLIC POLICY-PARKSIDE HS  2013    305   \n",
       "756   CESAR CHAVEZ PCS FOR PUBLIC POLICY CHAVEZ PREP  2013    322   \n",
       "\n",
       "     TOTAL_RESTRAINT_SECLUDE  TOTAL_RESTRAINT_SECLUDE_rate  \n",
       "751                    0.000                         0.000  \n",
       "752                    0.000                         0.000  \n",
       "754                    0.000                         0.000  \n",
       "755                    0.000                         0.000  \n",
       "756                    0.000                         0.000  "
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_summary = aggregate_crdc(data = crdc_disc_foragg,\n",
    "                             var_col = \"total_discipline\", \n",
    "                            value_col = \"total_discipline\",\n",
    "                             format = \"wide\")\n",
    "\n",
    "crdc_res_foragg = crdc_largerpull_fill.loc[~crdc_largerpull_fill.enrollment.isin(['0',\n",
    "                                        'Not applicable']),\n",
    "                                        ['school_name', 'year',\n",
    "                                        'enrollment',\n",
    "                                        'total_restraint_seclude']].copy()\n",
    "crdc_res_foragg.rename(columns = {'enrollment':\n",
    "            'total'}, inplace = True)\n",
    "\n",
    "res_summary = aggregate_crdc(data = crdc_res_foragg,\n",
    "                             var_col = \"total_restraint_seclude\", \n",
    "                            value_col = \"total_restraint_seclude\",\n",
    "                             format = \"wide\")\n",
    "\n",
    "\n",
    "\n",
    "res_summary.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 merge the diff crdc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_summary.rename(columns = {'TOTAL': 'total_students_ressec_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "disc_summary.rename(columns = {'TOTAL': 'total_students_disc_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "iep_summary.rename(columns = {'TOTAL': 'total_students_iep_data'},\n",
    "                  inplace = True)\n",
    "\n",
    "res_exclude_year = [col for col in res_summary.columns if col != \"YEAR\"]\n",
    "disc_exclude_year = [col for col in disc_summary.columns if col != \"YEAR\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nces_name</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504</th>\n",
       "      <th>total_students_iep_data</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504_rate</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA_rate</th>\n",
       "      <th>total_students_ressec_data</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE_rate</th>\n",
       "      <th>total_students_disc_data</th>\n",
       "      <th>TOTAL_DISCIPLINE</th>\n",
       "      <th>TOTAL_DISCIPLINE_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY ACADEMY PCS</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.000</td>\n",
       "      <td>355.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>nan</td>\n",
       "      <td>382.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>382.000</td>\n",
       "      <td>205.000</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY PCS-ELEMENTARY</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>nan</td>\n",
       "      <td>233.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>233.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITON ES</td>\n",
       "      <td>26.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>249.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.104</td>\n",
       "      <td>247.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>247.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMIDON BOWEN  ES</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.147</td>\n",
       "      <td>342.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>342.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANACOSTIA SHS</td>\n",
       "      <td>224.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>766.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.292</td>\n",
       "      <td>751.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>751.000</td>\n",
       "      <td>338.000</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                nces_name  \\\n",
       "0     ACHIEVEMENT PREPARATORY ACADEMY PCS   \n",
       "1  ACHIEVEMENT PREPARATORY PCS-ELEMENTARY   \n",
       "2                                AITON ES   \n",
       "3                        AMIDON BOWEN  ES   \n",
       "4                           ANACOSTIA SHS   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA  \\\n",
       "0                                           nan   \n",
       "1                                           nan   \n",
       "2                                        26.000   \n",
       "3                                        50.000   \n",
       "4                                       224.000   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504  \\\n",
       "0                                              7.000     \n",
       "1                                              2.000     \n",
       "2                                              4.000     \n",
       "3                                              2.000     \n",
       "4                                              7.000     \n",
       "\n",
       "   total_students_iep_data  \\\n",
       "0                  355.000   \n",
       "1                  222.000   \n",
       "2                  249.000   \n",
       "3                  341.000   \n",
       "4                  766.000   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504_rate  \\\n",
       "0                                              0.020          \n",
       "1                                              0.009          \n",
       "2                                              0.016          \n",
       "3                                              0.006          \n",
       "4                                              0.009          \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA_rate  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2                                              0.104   \n",
       "3                                              0.147   \n",
       "4                                              0.292   \n",
       "\n",
       "   total_students_ressec_data  TOTAL_RESTRAINT_SECLUDE  \\\n",
       "0                     382.000                    0.000   \n",
       "1                     233.000                    0.000   \n",
       "2                     247.000                    0.000   \n",
       "3                     342.000                    0.000   \n",
       "4                     751.000                    0.000   \n",
       "\n",
       "   TOTAL_RESTRAINT_SECLUDE_rate  total_students_disc_data  TOTAL_DISCIPLINE  \\\n",
       "0                         0.000                   382.000           205.000   \n",
       "1                         0.000                   233.000            20.000   \n",
       "2                         0.000                   247.000            57.000   \n",
       "3                         0.000                   342.000            69.000   \n",
       "4                         0.000                   751.000           338.000   \n",
       "\n",
       "   TOTAL_DISCIPLINE_rate  \n",
       "0                  0.537  \n",
       "1                  0.086  \n",
       "2                  0.231  \n",
       "3                  0.202  \n",
       "4                  0.450  "
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## merge all three crdc \n",
    "dfs_crdc = [df.set_index(['SCHOOL_NAME']) for df in [iep_summary, \n",
    "                                                    res_summary[res_exclude_year],\n",
    "                                                    disc_summary[disc_exclude_year]]]\n",
    "\n",
    "crdc_rates_tomerge  = pd.concat(dfs_crdc, axis=1).reset_index().rename(columns = {'index': 'nces_name'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate and merge with complaints data\n",
    "\n",
    "Count of complaints 2014 onwards --- 2013-2014 demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_agg = [\"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "dc_filings_postdem = dc_filings_totalbyschool.loc[dc_filings_totalbyschool.year.isin(years_agg)].groupby(['nces_name',\n",
    "                                        'casetype_final']).agg({'count_filings': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "cc_dem_rates_20132014 = cc_dem_rates.loc[cc_dem_rates.which_year == \"_2013-14\"].copy()\n",
    "\n",
    "\n",
    "## reshape filings to wide\n",
    "dc_filings_postdem_wide = pd.pivot_table(dc_filings_postdem,\n",
    "                                        index = ['nces_name'],\n",
    "                                        columns = ['casetype_final'],\n",
    "                                        values = 'count_filings').reset_index()\n",
    "\n",
    "dc_filings_postdem_wide.columns = [re.sub(\"\\s\", \"_\", col.upper())\n",
    "                                  for col in dc_filings_postdem_wide.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nces_name</th>\n",
       "      <th>which_year</th>\n",
       "      <th>frpl_eligible_rate</th>\n",
       "      <th>black_rate</th>\n",
       "      <th>white_rate</th>\n",
       "      <th>hispanic_rate</th>\n",
       "      <th>NCES_NAME</th>\n",
       "      <th>AGAINST_LEA</th>\n",
       "      <th>AGAINST_SEA</th>\n",
       "      <th>BY_LEA</th>\n",
       "      <th>EXPEDITED_DISCIPLINE</th>\n",
       "      <th>in_filings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACADEMY OF HOPE ADULT PCS</td>\n",
       "      <td>_2013-14</td>\n",
       "      <td>0.948</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY PCS ELEMENTARY</td>\n",
       "      <td>_2013-14</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>ACHIEVEMENT PREPARATORY PCS ELEMENTARY</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY PCS MIDDLE SCHOOL</td>\n",
       "      <td>_2013-14</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADAMS ELEMENTARY SCHOOL                       ...</td>\n",
       "      <td>_2013-14</td>\n",
       "      <td>0.984</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ADAMS ELEMENTARY SCHOOL                       ...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADVANCED PATH ACADEMY</td>\n",
       "      <td>_2013-14</td>\n",
       "      <td>0.984</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           nces_name which_year  \\\n",
       "0                          ACADEMY OF HOPE ADULT PCS   _2013-14   \n",
       "1             ACHIEVEMENT PREPARATORY PCS ELEMENTARY   _2013-14   \n",
       "2          ACHIEVEMENT PREPARATORY PCS MIDDLE SCHOOL   _2013-14   \n",
       "3  ADAMS ELEMENTARY SCHOOL                       ...   _2013-14   \n",
       "4                              ADVANCED PATH ACADEMY   _2013-14   \n",
       "\n",
       "   frpl_eligible_rate  black_rate  white_rate  hispanic_rate  \\\n",
       "0               0.948         nan         nan            nan   \n",
       "1               0.931       1.000       0.000          0.000   \n",
       "2               0.931       1.000       0.000          0.000   \n",
       "3               0.984         nan         nan            nan   \n",
       "4               0.984         nan         nan            nan   \n",
       "\n",
       "                                           NCES_NAME  AGAINST_LEA  \\\n",
       "0                                                NaN        0.000   \n",
       "1             ACHIEVEMENT PREPARATORY PCS ELEMENTARY        7.000   \n",
       "2                                                NaN        0.000   \n",
       "3  ADAMS ELEMENTARY SCHOOL                       ...        5.000   \n",
       "4                                                NaN        0.000   \n",
       "\n",
       "   AGAINST_SEA  BY_LEA  EXPEDITED_DISCIPLINE  in_filings  \n",
       "0        0.000   0.000                 0.000           0  \n",
       "1        0.000   0.000                 1.000           1  \n",
       "2        0.000   0.000                 0.000           0  \n",
       "3        0.000   0.000                 0.000           1  \n",
       "4        0.000   0.000                 0.000           0  "
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nces_name</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504</th>\n",
       "      <th>total_students_iep_data</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504_rate</th>\n",
       "      <th>STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA_rate</th>\n",
       "      <th>total_students_ressec_data</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE</th>\n",
       "      <th>TOTAL_RESTRAINT_SECLUDE_rate</th>\n",
       "      <th>total_students_disc_data</th>\n",
       "      <th>TOTAL_DISCIPLINE</th>\n",
       "      <th>TOTAL_DISCIPLINE_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY ACADEMY PCS</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.000</td>\n",
       "      <td>355.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>nan</td>\n",
       "      <td>382.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>382.000</td>\n",
       "      <td>205.000</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACHIEVEMENT PREPARATORY PCS-ELEMENTARY</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>nan</td>\n",
       "      <td>233.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>233.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMIDON BOWEN  ES</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.147</td>\n",
       "      <td>342.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>342.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANACOSTIA SHS</td>\n",
       "      <td>224.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>766.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.292</td>\n",
       "      <td>751.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>751.000</td>\n",
       "      <td>338.000</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>APPLETREE EARLY LEARNING CENTER PCS COLUMBIA H...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>170.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>161.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>161.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           nces_name  \\\n",
       "0                ACHIEVEMENT PREPARATORY ACADEMY PCS   \n",
       "1             ACHIEVEMENT PREPARATORY PCS-ELEMENTARY   \n",
       "3                                   AMIDON BOWEN  ES   \n",
       "4                                      ANACOSTIA SHS   \n",
       "5  APPLETREE EARLY LEARNING CENTER PCS COLUMBIA H...   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA  \\\n",
       "0                                           nan   \n",
       "1                                           nan   \n",
       "3                                        50.000   \n",
       "4                                       224.000   \n",
       "5                                         8.000   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504  \\\n",
       "0                                              7.000     \n",
       "1                                              2.000     \n",
       "3                                              2.000     \n",
       "4                                              7.000     \n",
       "5                                              0.000     \n",
       "\n",
       "   total_students_iep_data  \\\n",
       "0                  355.000   \n",
       "1                  222.000   \n",
       "3                  341.000   \n",
       "4                  766.000   \n",
       "5                  170.000   \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_SECTION_504_rate  \\\n",
       "0                                              0.020          \n",
       "1                                              0.009          \n",
       "3                                              0.006          \n",
       "4                                              0.009          \n",
       "5                                              0.000          \n",
       "\n",
       "   STUDENTS_WITH_DISABILITIES_SERVED_UNDER_IDEA_rate  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "3                                              0.147   \n",
       "4                                              0.292   \n",
       "5                                              0.047   \n",
       "\n",
       "   total_students_ressec_data  TOTAL_RESTRAINT_SECLUDE  \\\n",
       "0                     382.000                    0.000   \n",
       "1                     233.000                    0.000   \n",
       "3                     342.000                    0.000   \n",
       "4                     751.000                    0.000   \n",
       "5                     161.000                    0.000   \n",
       "\n",
       "   TOTAL_RESTRAINT_SECLUDE_rate  total_students_disc_data  TOTAL_DISCIPLINE  \\\n",
       "0                         0.000                   382.000           205.000   \n",
       "1                         0.000                   233.000            20.000   \n",
       "3                         0.000                   342.000            69.000   \n",
       "4                         0.000                   751.000           338.000   \n",
       "5                         0.000                   161.000             0.000   \n",
       "\n",
       "   TOTAL_DISCIPLINE_rate  \n",
       "0                  0.537  \n",
       "1                  0.086  \n",
       "3                  0.202  \n",
       "4                  0.450  \n",
       "5                  0.000  "
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## na indicates there were not cases of a particular type\n",
    "## so filling in with 0\n",
    "dc_filings_postdem_tomerge = dc_filings_postdem_wide[['NCES_NAME',\n",
    "                                                    'AGAINST_LEA',\n",
    "                                                    'AGAINST_SEA',\n",
    "                                                    'BY_LEA',\n",
    "                                                     'EXPEDITED_DISCIPLINE']].fillna(0)\n",
    "\n",
    "## left join with common core demographics\n",
    "cc_dem_rates_wcase = pd.merge(cc_dem_rates_20132014,\n",
    "                             dc_filings_postdem_tomerge,\n",
    "                             left_on = 'nces_name',\n",
    "                             right_on = 'NCES_NAME',\n",
    "                             how = \"left\")\n",
    "\n",
    "## 0 = indicates no cases\n",
    "case_vars = [col for col in cc_dem_rates_wcase.columns if \n",
    "            \"LEA\" in col or \"AGAINST\" in col or \"EXPEDITED\" in col]\n",
    "\n",
    "cc_dem_rates_wcase[case_vars] = cc_dem_rates_wcase[case_vars].fillna(0)\n",
    "cc_dem_rates_wcase['in_filings'] = np.where(cc_dem_rates_wcase.NCES_NAME.isnull(), \n",
    "                                           0, 1)\n",
    "\n",
    "\n",
    "## look at overlap\n",
    "names_shared = set(cc_dem_rates_wcase.nces_name).intersection(crdc_rates_tomerge.nces_name)\n",
    "names_ccd_notcr = set(cc_dem_rates_wcase.nces_name).difference(crdc_rates_tomerge.nces_name)\n",
    "#names_ccd_notcr\n",
    "\n",
    "names_cr_notccd = set(crdc_rates_tomerge.nces_name).difference(cc_dem_rates_wcase.nces_name)\n",
    "\n",
    "## do fuzzy matching and then merge in ccd demographics\n",
    "## after that merge\n",
    "## for now, just use frpl data\n",
    "\n",
    "cc_notmatched = cc_dem_rates_wcase.loc[cc_dem_rates_wcase.nces_name.isin(names_ccd_notcr)].copy()\n",
    "cc_notmatched.to_csv(base_path + \"data/dc/intermediate/commoncore_tomatch.csv\",\n",
    "                    index = False)\n",
    "\n",
    "\n",
    "\n",
    "cr_notmatched = crdc_rates_tomerge.loc[crdc_rates_tomerge.nces_name.isin(names_cr_notccd)].copy()\n",
    "cr_notmatched.to_csv(base_path + \"data/dc/intermediate/ccd_pool.csv\",\n",
    "                    index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nces_name', 'which_year', 'frpl_eligible_rate', 'black_rate',\n",
       "       'white_rate', 'hispanic_rate', 'NCES_NAME', 'AGAINST_LEA',\n",
       "       'AGAINST_SEA', 'BY_LEA', 'EXPEDITED_DISCIPLINE', 'in_filings',\n",
       "       'nces_name_formatch', 'ccd_name_formatch', 'nces_name_tomerge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in match results\n",
    "cc_cr_match = pd.read_csv(base_path + \"data/dc/intermediate/nces_civilrightsdf_fuzzymatch.csv\")\n",
    "cc_cr_match.rename(columns = {'original_name': 'nces_name_formatch',\n",
    "                             'matched_name': 'ccd_name_formatch'}, inplace = True)\n",
    "\n",
    "## merge\n",
    "cc_wccdnames = pd.merge(cc_dem_rates_wcase,\n",
    "                       cc_cr_match[['nces_name_formatch',\n",
    "                                   'ccd_name_formatch']],\n",
    "                       left_on = \"nces_name\",\n",
    "                       right_on = \"nces_name_formatch\",\n",
    "                       how = \"left\")\n",
    "\n",
    "## create var to merge on\n",
    "cc_wccdnames['nces_name_tomerge'] = np.where(cc_wccdnames.ccd_name_formatch.isnull(),\n",
    "                                            cc_wccdnames.nces_name,\n",
    "                                            cc_wccdnames.ccd_name_formatch)\n",
    "\n",
    "\n",
    "## now left join\n",
    "case_ccd_cr = pd.merge(cc_wccdnames.drop(['nces_name'], axis = 1),\n",
    "                      crdc_rates_tomerge,\n",
    "                      left_on = \"nces_name_tomerge\",\n",
    "                      right_on = \"nces_name\",\n",
    "                      how = \"left\")\n",
    "\n",
    "## write csv\n",
    "case_ccd_cr.to_csv(base_path + \"data/dc/cleaned/filings_withdem.csv\",\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## where things left off:\n",
    "## - fuzzy matching nces and ccd\n",
    "## next steps:\n",
    "## - load in matched data\n",
    "## - get better ids\n",
    "## - do left join on nces and hopefully more schools also have ccd data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
